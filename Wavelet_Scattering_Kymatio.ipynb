{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Wavelet_Scattering_Kymatio.ipynb","provenance":[],"mount_file_id":"1awSWU0pv6IMWR8JJba2XB7ukqVFn8uqN","authorship_tag":"ABX9TyO6XqBw6YiNCobSn+3DxI+6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"0PhQV6P5vchD","colab_type":"text"},"source":["Importando as principais bibliotecas, intalando Kymatio\n"]},{"cell_type":"code","metadata":{"id":"0Fsp3tbc6tTO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"executionInfo":{"status":"ok","timestamp":1599179475315,"user_tz":180,"elapsed":73377,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}},"outputId":"88e364a7-3c58-474a-c57d-62fb191ea322"},"source":["from importlib.machinery import SourceFileLoader\n","#dataset = SourceFileLoader('dataset', '/content/drive/My Drive/Colab Notebooks/Libraries/dataset.py').load_module()\n","#models = SourceFileLoader('models','/content/drive/My Drive/Colab Notebooks/Libraries/models.py').load_module()\n","!pip install wget\n","import wget\n","data = wget.download('https://storage.googleapis.com/download.tensorflow.org/data/speech_commands_v0.01.tar.gz') \n","import tarfile\n","data = tarfile.open(data)\n","data.extractall()\n","import numpy as np\n","from sklearn.metrics import accuracy_score\n","!pip install kymatio\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import os\n","\n","\n","# Preliminaries\n","# -------------\n","#\n","# Since we're using TensorFlow and Keras to train the model, import the\n","# relevant modules.\n","\n","import tensorflow as tf\n","\n","from tensorflow.keras import layers\n","\n","# Finally, we import the `Scattering1D` class from the `kymatio.keras` package\n","# and the `fetch_fsdd` function from `kymatio.datasets`. The `Scattering1D`\n","# class is what lets us calculate the scattering transform, while the\n","# `fetch_fsdd` function downloads the FSDD, if needed.\n","\n","#from kymatio.keras import Scattering1D\n","from kymatio.datasets import fetch_fsdd\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: wget in /usr/local/lib/python3.6/dist-packages (3.2)\n","Requirement already satisfied: kymatio in /usr/local/lib/python3.6/dist-packages (0.2.0)\n","Requirement already satisfied: configparser in /usr/local/lib/python3.6/dist-packages (from kymatio) (5.0.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from kymatio) (1.18.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from kymatio) (20.4)\n","Requirement already satisfied: appdirs in /usr/local/lib/python3.6/dist-packages (from kymatio) (1.4.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from kymatio) (1.4.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->kymatio) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->kymatio) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pzaTyAV9vOLI","colab_type":"text"},"source":["Definindo as variáveis, criando um DataFrame que facilite para manipular os dados\n","\n"]},{"cell_type":"code","metadata":{"id":"xxnG88rXFyNl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1599179476350,"user_tz":180,"elapsed":71236,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}},"outputId":"fc647a5f-4606-44da-c2b7-2fc6a47ee2dd"},"source":["from glob import glob\n","DIR = '/content'\n","\n","LABELS = 'go stop off right left down on up yes no'.split()\n","NUM_CLASSES = len(LABELS)\n","data = []\n","# Get all paths inside DIR that ends with wav\n","wav_files = glob(os.path.join(DIR, '*/*wav'))\n","wav_files = [x.split(sep='/')[2] + '/' + x.split(sep='/')[3] for x in wav_files]\n","for e in wav_files:\n","  label = e.split('/')[0]\n","  speaker = e.split('/')[1].split('_')[0]\n","  if label in LABELS:\n","    fil = os.path.join(DIR, e)\n","    data.append([label,fil,speaker])\n","  else:\n","    fil = os.path.join(DIR, e)\n","    data.append(['unknown',fil,speaker])\n","df = pd.DataFrame(data,columns=['label','path','speaker'])\n","df.head()\n","#wav_files[2].split('/')[1].split('_')[0]"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>path</th>\n","      <th>speaker</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>unknown</td>\n","      <td>/content/happy/f42e234b_nohash_0.wav</td>\n","      <td>f42e234b</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>unknown</td>\n","      <td>/content/happy/0ac15fe9_nohash_0.wav</td>\n","      <td>0ac15fe9</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>unknown</td>\n","      <td>/content/happy/a5d485dc_nohash_0.wav</td>\n","      <td>a5d485dc</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>unknown</td>\n","      <td>/content/happy/f5e5e8b0_nohash_0.wav</td>\n","      <td>f5e5e8b0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>unknown</td>\n","      <td>/content/happy/ead2934a_nohash_1.wav</td>\n","      <td>ead2934a</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     label                                  path   speaker\n","0  unknown  /content/happy/f42e234b_nohash_0.wav  f42e234b\n","1  unknown  /content/happy/0ac15fe9_nohash_0.wav  0ac15fe9\n","2  unknown  /content/happy/a5d485dc_nohash_0.wav  a5d485dc\n","3  unknown  /content/happy/f5e5e8b0_nohash_0.wav  f5e5e8b0\n","4  unknown  /content/happy/ead2934a_nohash_1.wav  ead2934a"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"4sD2yCGXkkep","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1599179788386,"user_tz":180,"elapsed":1403,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}},"outputId":"d61c20f5-9209-4178-dc3b-ab5fd964194c"},"source":["df['label'].value_counts()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["unknown    41045\n","stop        2380\n","yes         2377\n","up          2375\n","no          2375\n","go          2372\n","on          2367\n","right       2367\n","down        2359\n","off         2357\n","left        2353\n","Name: label, dtype: int64"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"0pwnHAnE2J_e","colab_type":"text"},"source":["Filtrando dados "]},{"cell_type":"code","metadata":{"id":"3C2_QRvcwYBF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599179796090,"user_tz":180,"elapsed":2090,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}}},"source":["probIncludeUnknown = 0.1\n","isUnknown = df['label']=='unknown'\n","df2 = df[isUnknown]\n","df2 = df2.sample(frac=probIncludeUnknown,replace=True,random_state=32)\n","df3 = df[~isUnknown]\n","df = pd.concat([df2,df3])\n"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-7rAezymcTT2","colab_type":"text"},"source":["Removendo a classe \"Unknown\", pois aparentemente a Wavelet Scattering não lida bem com ela."]},{"cell_type":"code","metadata":{"id":"FeDaRdVT1AU8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599179799247,"user_tz":180,"elapsed":2055,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}}},"source":["df3['label'].value_counts()\n","df = df3"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"nFurMtbJzrQZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599179804753,"user_tz":180,"elapsed":3456,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}}},"source":["count=[]\n","for e in df['speaker'].unique():\n","  x = df['speaker'] == e\n","  count.append([str(e),str(x.sum())])\n","count = np.array(count)\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"0oal28t2-snf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"status":"ok","timestamp":1597806624389,"user_tz":180,"elapsed":21108,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}},"outputId":"097ccdbd-101f-45f9-e930-de36dd19471f"},"source":["import matplotlib.pyplot as plt\n","x = count[:,0]\n","y = count[:,1]\n","#y = count[1]\n","#type(x[1])\n","plt.bar(y,x)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<BarContainer object of 1841 artists>"]},"metadata":{"tags":[]},"execution_count":11},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"GP-dibC_LZl0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599179804756,"user_tz":180,"elapsed":2653,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}}},"source":["include_speaker = []\n","for i in range(len(count)):\n","  if int(count[i,1])>=50:\n","    include_speaker.append(count[i,0])\n","include_speaker = np.array(include_speaker)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"KvWlNZtOw0Wj","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599179817060,"user_tz":180,"elapsed":1047,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}}},"source":["include_speaker_random = np.random.choice(include_speaker,10)\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"LcG7JnWFOe6a","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599179820165,"user_tz":180,"elapsed":1711,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}}},"source":["include = []\n","for e in df['speaker']:\n","  include.append(e in include_speaker_random)\n","\n","df2 = df[include]"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"-UulFmMTU-VM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1599179825550,"user_tz":180,"elapsed":1416,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}},"outputId":"ac1f9cb5-1c68-403b-ae13-02ae849576af"},"source":["df2['label'].value_counts()"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["go       51\n","on       51\n","no       51\n","down     50\n","right    50\n","up       50\n","yes      50\n","stop     50\n","left     50\n","off      50\n","Name: label, dtype: int64"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"0umeLGJ-cjF6","colab_type":"text"},"source":["Como a Wavelet Scattering é uma técnica desenvolvida visando extrair características de datasets pequenos, inclui apenas uma fração do dataset para treinar a cada vez."]},{"cell_type":"code","metadata":{"id":"gxd0cCfXbX01","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1598281176591,"user_tz":180,"elapsed":65746,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}},"outputId":"161f56e8-2f03-4235-f43c-4eee9d0bff0e"},"source":["dropProb = 0.450\n","df = df.sample(frac=dropProb)\n","df['label'].value_counts()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["on       1113\n","left     1094\n","right    1079\n","no       1078\n","off      1077\n","up       1070\n","go       1057\n","down     1045\n","stop     1023\n","yes      1021\n","Name: label, dtype: int64"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"EU8KwKG_g3a4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599180095892,"user_tz":180,"elapsed":891,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}}},"source":["df = df2"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sklYgt3pdSch","colab_type":"text"},"source":["Convertendo as labels para variáveis numéricas."]},{"cell_type":"code","metadata":{"id":"4rmfCHCfV87H","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599180098010,"user_tz":180,"elapsed":842,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}},"outputId":"d98754f4-4ffb-46d8-eba3-834e073c5a67"},"source":["target = []\n","for u in df['label'].values:\n","  if u in LABELS:\n","    target.append(LABELS.index(u))\n","  else:\n","    target.append(len(LABELS)+1)\n","target = np.array(target)\n","target.shape\n","np.unique(target)"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"yv4-bhwL2Pv8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596950238719,"user_tz":180,"elapsed":75541,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}},"outputId":"a61d4209-14a3-4340-eb6a-20c71d4e37de"},"source":["if 'no' in LABELS:\n","  print('Entrou!')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Entrou!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3_THpiPqKBsb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597429475300,"user_tz":180,"elapsed":1797,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}},"outputId":"db8b5974-1bfd-4a47-e390-553740d52531"},"source":["from distutils.dir_util import copy_tree\n","\n","copy_tree('/content/drive/My Drive/Compras/lib','/usr/local/lib/python3.6/dist-packages/kymatio/scattering1d/')\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/usr/local/lib/python3.6/dist-packages/kymatio/scattering1d/filter_bank.py']"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"NIEBPcBE3gRU","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599179844282,"user_tz":180,"elapsed":827,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}}},"source":["###############################################################################\n","# Pipeline setup\n","# --------------\n","# We start by specifying the dimensions of our processing pipeline along with\n","# some other parameters.\n","#\n","# First, we have signal length. Longer signals are truncated and shorter\n","# signals are zero-padded. The sampling rate is 8000 Hz, so this corresponds to\n","# little over a second.\n","from kymatio.keras import Scattering1D\n","\n","\n","T = 2 ** 14"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"w5wAp56h2oKc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597877177096,"user_tz":180,"elapsed":505,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}},"outputId":"3e547c29-c24b-448c-8451-4f4cb894d2f6"},"source":["_,x = wavfile.read('/content/eight/012c8314_nohash_0.wav')\n","x = np.asarray(x, dtype='float')\n","wav_time_stch = librosa.effects.time_stretch(x,factor)\n","len(wav_roll)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["16000"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"VQpyogbgdolm","colab_type":"text"},"source":["Criando a matriz com os sinais para treinamento e o target."]},{"cell_type":"code","metadata":{"id":"xX9ei41nPHvu","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599180113651,"user_tz":180,"elapsed":10292,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}}},"source":["from scipy.io import wavfile\n","from scipy import signal\n","import librosa\n","import librosa.display\n","\n","x_all = np.zeros((3*len(df['label']), T))\n","y_all = np.zeros(3*len(df['label']), dtype=np.uint8)\n","#subset = np.zeros(len(df['label']), dtype=np.uint8)\n","#y_all = []\n","#x_all = []\n","\n","for k,w in enumerate(df['path']):\n","  y = target[k]\n","  #y = df['label'].values[k]\n","  _,x = wavfile.read(w)\n","  #x = signal.resample(x,2**13)\n","  x = np.asarray(x, dtype='float')\n","  x /= np.max(np.abs(x))\n","      # If it's too long, truncate it.\n","  if len(x) > T:\n","    x = x[:T]\n","\n","  # If it's too short, zero-pad it.\n","  start = (T - len(x)) // 2\n","\n","  #data augmentation by time stretching \n","\n","  #factor = 0.4\n","  #wav_time_stch = librosa.effects.time_stretch(x,factor)\n","\n","  #data augmentation by time shifting the wave\n","  wav_roll = np.roll(x,int(16000/10))\n","\n","  #data augmentation by pitch shifting\n","  wav_pitch_sf = librosa.effects.pitch_shift(x,16000,n_steps=-5)\n","\n","  x_all[k,start:start + len(x)] = x\n","  x_all[k+len(df['label']),start:start+len(x)] = wav_pitch_sf\n","  x_all[k+2*len(df['label']),start:start+len(x)] = wav_roll\n","  y_all[k] = y\n","  y_all[k+len(df['label'])] = y\n","  y_all[k+2*len(df['label'])] = y\n","\n","#x = np.array(x)\n","#y = np.array(y)\n","\n"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Ovp6Yvfd5Dl","colab_type":"text"},"source":["Dividir em Training Set e Testing Set"]},{"cell_type":"code","metadata":{"id":"miOqXON6ftHt","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(x_all,y_all,test_size=0.2,random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G8IhVyTR1YpM","colab_type":"code","colab":{}},"source":["x_all = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OUwyvbABgiGU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597877305275,"user_tz":180,"elapsed":614,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}},"outputId":"bbcd9be2-804c-46be-cfec-0e6801c44f90"},"source":["X_test.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(984, 16384)"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"VRycb7AwUiiV","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599180127299,"user_tz":180,"elapsed":956,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}}},"source":["# Maximum scale 2**J of the scattering transform (here, about 30 milliseconds)\n","# and the number of wavelets per octave.\n","T = 2**14\n","J = 13\n","#J = 13\n","Q = 14\n","# We need a small constant to add to the scattering coefficients before\n","# computing the logarithm. This prevents very large values when the scattering\n","# coefficients are very close to zero.\n","log_eps = 1e-6"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"kQildg_xTntq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":751},"executionInfo":{"status":"ok","timestamp":1599180182396,"user_tz":180,"elapsed":54022,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}},"outputId":"6da3814d-4d95-4f64-ac08-9e9bc6c575a5"},"source":["###############################################################################\n","# Log-scattering layer\n","# --------------------\n","# We now create a classification model using the `Scattering1D` Keras layer.\n","# First, we take the input signals of length `T`.\n","\n","x_in = layers.Input(shape=(T))\n","\n","###############################################################################\n","# These are fed into the `Scattering1D` layer.\n","\n","x = Scattering1D(J, Q=Q)(x_in)\n","\n","###############################################################################\n","# Since it does not carry useful information, we remove the zeroth-order\n","# scattering coefficients, which are always placed in the first channel of\n","# the scattering transform.\n","\n","x = layers.Lambda(lambda x: x[..., 1:, :])(x)\n","\n","# To increase discriminability, we take the logarithm of the scattering\n","# coefficients (after adding a small constant to make sure nothing blows up\n","# when scattering coefficients are close to zero). This is known as the\n","# log-scattering transform.\n","\n","x = layers.Lambda(lambda x: tf.math.log(tf.abs(x) + log_eps))(x)\n","\n","###############################################################################\n","# We then average along the last dimension (time) to get a time-shift\n","# invariant representation.\n","\n","x = layers.GlobalAveragePooling1D(data_format='channels_first')(x)\n","\n","###############################################################################\n","# Finally, we apply batch normalization to ensure that the data is within a\n","# moderate range.\n","\n","x = layers.BatchNormalization(axis=1)(x)\n","\n","###############################################################################\n","# These features are then used to classify the input signal using a dense\n","# layer followed by a softmax activation.\n","\n","x_out = layers.Dense(11, activation='softmax')(x)\n","\n","###############################################################################\n","# Finally, we create the model and display it.\n","\n","model = tf.keras.models.Model(x_in, x_out)\n","model.summary()\n"],"execution_count":22,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fdb86388ea0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: Unable to identify source code of lambda function <function <lambda> at 0x7fdb86388ea0>. It was defined in this code:\n","backend.fft = FFT(lambda x: tf.signal.fft(x, name='fft1d'),\n","                  lambda x: tf.signal.ifft(x, name='ifft1d'),\n","                  lambda x: tf.math.real(tf.signal.ifft(x, name='irfft1d')),\n","                  lambda x: None)\n","\n","This code must contain a single distinguishable lambda. To avoid this problem, define each lambda in a separate expression.\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <function <lambda> at 0x7fdb86388ea0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: Unable to identify source code of lambda function <function <lambda> at 0x7fdb86388ea0>. It was defined in this code:\n","backend.fft = FFT(lambda x: tf.signal.fft(x, name='fft1d'),\n","                  lambda x: tf.signal.ifft(x, name='ifft1d'),\n","                  lambda x: tf.math.real(tf.signal.ifft(x, name='irfft1d')),\n","                  lambda x: None)\n","\n","This code must contain a single distinguishable lambda. To avoid this problem, define each lambda in a separate expression.\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","Model: \"functional_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 16384)]           0         \n","_________________________________________________________________\n","scattering1d (Scattering1D)  (None, 1096, 2)           0         \n","_________________________________________________________________\n","lambda (Lambda)              (None, 1095, 2)           0         \n","_________________________________________________________________\n","lambda_1 (Lambda)            (None, 1095, 2)           0         \n","_________________________________________________________________\n","global_average_pooling1d (Gl (None, 1095)              0         \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 1095)              4380      \n","_________________________________________________________________\n","dense (Dense)                (None, 11)                12056     \n","=================================================================\n","Total params: 16,436\n","Trainable params: 14,246\n","Non-trainable params: 2,190\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o9a1Vlv4kGgM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":768},"executionInfo":{"status":"error","timestamp":1599181258202,"user_tz":180,"elapsed":2274,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}},"outputId":"9d7bc747-0ca1-4bb0-d55a-10d29a2aad92"},"source":["model = model.load_weights('/content/drive/My Drive/Colab Notebooks/Kymatio/my_model_weights.index')"],"execution_count":23,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/util.py:1298: NameBasedSaverStatus.__init__ (from tensorflow.python.training.tracking.util) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.\n"],"name":"stdout"},{"output_type":"error","ename":"AssertionError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-6633a4fffa16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Colab Notebooks/Kymatio/my_model_weights.index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2191\u001b[0m         \u001b[0;31m# streaming restore for any variables created in the future.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2192\u001b[0m         \u001b[0mtrackable_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreaming_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2193\u001b[0;31m       \u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_nontrivial_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2194\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36massert_nontrivial_match\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     \u001b[0;31m# assert_nontrivial_match and assert_consumed (and both are less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;31m# useful since we don't touch Python objects or Python state).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_consumed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_gather_saveable_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36massert_consumed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    981\u001b[0m       raise AssertionError(\n\u001b[1;32m    982\u001b[0m           \"Some objects had attributes which were not restored:{}\".format(\n\u001b[0;32m--> 983\u001b[0;31m               \"\".join(unused_attribute_strings)))\n\u001b[0m\u001b[1;32m    984\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrackable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: Some objects had attributes which were not restored:\n    <tf.Variable 'batch_normalization/gamma:0' shape=(1095,) dtype=float32, numpy=array([1., 1., 1., ..., 1., 1., 1.], dtype=float32)>: ['batch_normalization/gamma']\n    <tf.Variable 'batch_normalization/beta:0' shape=(1095,) dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>: ['batch_normalization/beta']\n    <tf.Variable 'batch_normalization/moving_mean:0' shape=(1095,) dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>: ['batch_normalization/moving_mean']\n    <tf.Variable 'batch_normalization/moving_variance:0' shape=(1095,) dtype=float32, numpy=array([1., 1., 1., ..., 1., 1., 1.], dtype=float32)>: ['batch_normalization/moving_variance']\n    <tf.Variable 'dense/kernel:0' shape=(1095, 11) dtype=float32, numpy=\narray([[-0.06552539,  0.00150196,  0.04957883, ...,  0.00170032,\n         0.05652288,  0.02877739],\n       [ 0.06041956,  0.00387365, -0.04097235, ..., -0.04674487,\n        -0.03195427, -0.04190894],\n       [-0.06084492, -0.00765617, -0.00954902, ...,  0.04122765,\n        -0.05098331,  0.0637432 ],\n       ...,\n       [-0.05263618, -0.05167732, -0.04668229, ..., -0.03524297,\n        -0.06415477, -0.01531001],\n       [-0.0303316 , -0.0254144 ,  0.00234061, ...,  0.05719368,\n         0.02624319,  0.04067329],\n       [ 0.06790657, -0.06116333, -0.05230214, ...,  0.05008856,\n        -0.02978819,  0.04186565]], dtype=float32)>: ['dense/kernel']\n    <tf.Variable 'dense/bias:0' shape=(11,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>: ['dense/bias']"]}]},{"cell_type":"code","metadata":{"id":"mvR6RqyxTuz-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598902299511,"user_tz":180,"elapsed":2571550,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}},"outputId":"0c0a2b1b-74eb-44f1-c35d-52951e039ce0"},"source":["\n","###############################################################################\n","# Training the classifier\n","# -----------------------\n","# Having set up the model, we attach an Adam optimizer and a cross-entropy\n","# loss function.\n","\n","opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n","\n","model.compile(optimizer=opt,\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","###############################################################################\n","# We then train the model using `model.fit`. The training data is given by\n","# those indices satisfying `subset == 0`.\n","\n","model.fit(X_train, y_train, epochs=200,\n","          batch_size=64, validation_split=0.2)\n","\n","###############################################################################\n","# Finally, we evaluate the model on the held-out test data. These are given by\n","# the indices `subset == 1`.\n","\n","model.evaluate(X_test, y_test, verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"functional_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_4 (InputLayer)         [(None, 16384)]           0         \n","_________________________________________________________________\n","scattering1d_3 (Scattering1D (None, 1096, 2)           0         \n","_________________________________________________________________\n","lambda_6 (Lambda)            (None, 1095, 2)           0         \n","_________________________________________________________________\n","lambda_7 (Lambda)            (None, 1095, 2)           0         \n","_________________________________________________________________\n","global_average_pooling1d_3 ( (None, 1095)              0         \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 1095)              4380      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 11)                12056     \n","=================================================================\n","Total params: 16,436\n","Trainable params: 14,246\n","Non-trainable params: 2,190\n","_________________________________________________________________\n","Epoch 1/200\n","16/16 [==============================] - 52s 3s/step - loss: 2.3761 - accuracy: 0.2129 - val_loss: 24.3021 - val_accuracy: 0.1245\n","Epoch 2/200\n","16/16 [==============================] - 11s 718ms/step - loss: 1.5983 - accuracy: 0.4455 - val_loss: 15.7721 - val_accuracy: 0.1867\n","Epoch 3/200\n","16/16 [==============================] - 12s 720ms/step - loss: 1.3980 - accuracy: 0.5286 - val_loss: 18.8548 - val_accuracy: 0.1245\n","Epoch 4/200\n","16/16 [==============================] - 12s 719ms/step - loss: 1.2937 - accuracy: 0.5670 - val_loss: 16.3410 - val_accuracy: 0.2158\n","Epoch 5/200\n","16/16 [==============================] - 12s 722ms/step - loss: 1.2007 - accuracy: 0.6085 - val_loss: 14.3758 - val_accuracy: 0.2490\n","Epoch 6/200\n","16/16 [==============================] - 12s 719ms/step - loss: 1.0987 - accuracy: 0.6501 - val_loss: 21.2301 - val_accuracy: 0.1618\n","Epoch 7/200\n","16/16 [==============================] - 12s 723ms/step - loss: 1.0544 - accuracy: 0.6729 - val_loss: 15.0254 - val_accuracy: 0.2573\n","Epoch 8/200\n","16/16 [==============================] - 12s 720ms/step - loss: 1.0210 - accuracy: 0.6926 - val_loss: 16.5862 - val_accuracy: 0.2158\n","Epoch 9/200\n","16/16 [==============================] - 11s 719ms/step - loss: 0.9882 - accuracy: 0.6989 - val_loss: 15.2976 - val_accuracy: 0.2199\n","Epoch 10/200\n","16/16 [==============================] - 12s 727ms/step - loss: 0.9546 - accuracy: 0.7092 - val_loss: 14.8825 - val_accuracy: 0.2199\n","Epoch 11/200\n","16/16 [==============================] - 11s 716ms/step - loss: 0.8826 - accuracy: 0.7487 - val_loss: 14.4053 - val_accuracy: 0.2199\n","Epoch 12/200\n","16/16 [==============================] - 11s 712ms/step - loss: 0.8738 - accuracy: 0.7456 - val_loss: 12.7670 - val_accuracy: 0.2199\n","Epoch 13/200\n","16/16 [==============================] - 11s 712ms/step - loss: 0.8522 - accuracy: 0.7259 - val_loss: 12.9643 - val_accuracy: 0.1743\n","Epoch 14/200\n","16/16 [==============================] - 11s 715ms/step - loss: 0.8202 - accuracy: 0.7539 - val_loss: 12.8520 - val_accuracy: 0.2241\n","Epoch 15/200\n","16/16 [==============================] - 11s 714ms/step - loss: 0.7745 - accuracy: 0.7778 - val_loss: 11.1994 - val_accuracy: 0.2158\n","Epoch 16/200\n","16/16 [==============================] - 12s 721ms/step - loss: 0.7638 - accuracy: 0.7726 - val_loss: 10.3397 - val_accuracy: 0.2158\n","Epoch 17/200\n","16/16 [==============================] - 12s 719ms/step - loss: 0.7515 - accuracy: 0.7799 - val_loss: 9.7331 - val_accuracy: 0.1826\n","Epoch 18/200\n","16/16 [==============================] - 12s 731ms/step - loss: 0.7867 - accuracy: 0.7664 - val_loss: 10.3836 - val_accuracy: 0.1701\n","Epoch 19/200\n","16/16 [==============================] - 12s 725ms/step - loss: 0.7630 - accuracy: 0.7809 - val_loss: 10.3736 - val_accuracy: 0.1950\n","Epoch 20/200\n","16/16 [==============================] - 12s 732ms/step - loss: 0.7035 - accuracy: 0.8131 - val_loss: 9.6164 - val_accuracy: 0.1577\n","Epoch 21/200\n","16/16 [==============================] - 12s 731ms/step - loss: 0.6936 - accuracy: 0.8089 - val_loss: 8.4022 - val_accuracy: 0.2116\n","Epoch 22/200\n","16/16 [==============================] - 12s 729ms/step - loss: 0.6783 - accuracy: 0.8183 - val_loss: 8.7907 - val_accuracy: 0.1992\n","Epoch 23/200\n","16/16 [==============================] - 12s 724ms/step - loss: 0.6533 - accuracy: 0.8245 - val_loss: 7.2532 - val_accuracy: 0.2448\n","Epoch 24/200\n","16/16 [==============================] - 12s 721ms/step - loss: 0.6613 - accuracy: 0.8141 - val_loss: 6.4563 - val_accuracy: 0.2573\n","Epoch 25/200\n","16/16 [==============================] - 12s 728ms/step - loss: 0.6356 - accuracy: 0.8120 - val_loss: 6.0036 - val_accuracy: 0.2780\n","Epoch 26/200\n","16/16 [==============================] - 12s 727ms/step - loss: 0.6564 - accuracy: 0.8089 - val_loss: 5.9709 - val_accuracy: 0.2490\n","Epoch 27/200\n","16/16 [==============================] - 12s 727ms/step - loss: 0.6105 - accuracy: 0.8390 - val_loss: 4.9809 - val_accuracy: 0.2988\n","Epoch 28/200\n","16/16 [==============================] - 12s 720ms/step - loss: 0.5891 - accuracy: 0.8432 - val_loss: 4.4041 - val_accuracy: 0.3568\n","Epoch 29/200\n","16/16 [==============================] - 12s 720ms/step - loss: 0.5947 - accuracy: 0.8411 - val_loss: 3.8820 - val_accuracy: 0.3776\n","Epoch 30/200\n","16/16 [==============================] - 12s 726ms/step - loss: 0.5838 - accuracy: 0.8453 - val_loss: 3.4493 - val_accuracy: 0.3942\n","Epoch 31/200\n","16/16 [==============================] - 12s 726ms/step - loss: 0.5667 - accuracy: 0.8463 - val_loss: 3.2085 - val_accuracy: 0.4232\n","Epoch 32/200\n","16/16 [==============================] - 12s 721ms/step - loss: 0.5428 - accuracy: 0.8629 - val_loss: 2.9971 - val_accuracy: 0.4191\n","Epoch 33/200\n","16/16 [==============================] - 12s 723ms/step - loss: 0.5767 - accuracy: 0.8359 - val_loss: 2.7356 - val_accuracy: 0.4315\n","Epoch 34/200\n","16/16 [==============================] - 12s 725ms/step - loss: 0.5658 - accuracy: 0.8380 - val_loss: 2.4920 - val_accuracy: 0.4398\n","Epoch 35/200\n","16/16 [==============================] - 12s 726ms/step - loss: 0.5384 - accuracy: 0.8453 - val_loss: 2.2895 - val_accuracy: 0.4523\n","Epoch 36/200\n","16/16 [==============================] - 12s 724ms/step - loss: 0.4931 - accuracy: 0.8744 - val_loss: 2.0521 - val_accuracy: 0.4855\n","Epoch 37/200\n","16/16 [==============================] - 12s 726ms/step - loss: 0.5436 - accuracy: 0.8609 - val_loss: 1.8631 - val_accuracy: 0.4730\n","Epoch 38/200\n","16/16 [==============================] - 12s 724ms/step - loss: 0.5680 - accuracy: 0.8453 - val_loss: 1.6988 - val_accuracy: 0.4896\n","Epoch 39/200\n","16/16 [==============================] - 12s 723ms/step - loss: 0.5626 - accuracy: 0.8318 - val_loss: 1.5862 - val_accuracy: 0.5062\n","Epoch 40/200\n","16/16 [==============================] - 12s 725ms/step - loss: 0.5250 - accuracy: 0.8505 - val_loss: 1.4348 - val_accuracy: 0.5270\n","Epoch 41/200\n","16/16 [==============================] - 12s 724ms/step - loss: 0.5347 - accuracy: 0.8588 - val_loss: 1.3576 - val_accuracy: 0.5477\n","Epoch 42/200\n","16/16 [==============================] - 12s 722ms/step - loss: 0.5063 - accuracy: 0.8712 - val_loss: 1.3179 - val_accuracy: 0.5436\n","Epoch 43/200\n","16/16 [==============================] - 12s 723ms/step - loss: 0.5043 - accuracy: 0.8712 - val_loss: 1.1594 - val_accuracy: 0.6100\n","Epoch 44/200\n","16/16 [==============================] - 12s 720ms/step - loss: 0.4721 - accuracy: 0.8692 - val_loss: 1.0859 - val_accuracy: 0.6224\n","Epoch 45/200\n","16/16 [==============================] - 12s 722ms/step - loss: 0.4782 - accuracy: 0.8733 - val_loss: 1.0732 - val_accuracy: 0.6390\n","Epoch 46/200\n","16/16 [==============================] - 12s 723ms/step - loss: 0.5601 - accuracy: 0.8307 - val_loss: 1.0010 - val_accuracy: 0.6598\n","Epoch 47/200\n","16/16 [==============================] - 12s 725ms/step - loss: 0.4605 - accuracy: 0.8847 - val_loss: 0.9517 - val_accuracy: 0.6722\n","Epoch 48/200\n","16/16 [==============================] - 12s 722ms/step - loss: 0.4321 - accuracy: 0.8920 - val_loss: 0.9088 - val_accuracy: 0.6680\n","Epoch 49/200\n","16/16 [==============================] - 12s 723ms/step - loss: 0.4349 - accuracy: 0.8993 - val_loss: 0.8878 - val_accuracy: 0.7012\n","Epoch 50/200\n","16/16 [==============================] - 12s 726ms/step - loss: 0.4518 - accuracy: 0.8733 - val_loss: 0.8458 - val_accuracy: 0.6971\n","Epoch 51/200\n","16/16 [==============================] - 12s 732ms/step - loss: 0.4479 - accuracy: 0.8692 - val_loss: 0.8505 - val_accuracy: 0.7054\n","Epoch 52/200\n","16/16 [==============================] - 12s 725ms/step - loss: 0.4319 - accuracy: 0.8962 - val_loss: 0.8671 - val_accuracy: 0.7012\n","Epoch 53/200\n","16/16 [==============================] - 12s 725ms/step - loss: 0.4845 - accuracy: 0.8588 - val_loss: 0.8689 - val_accuracy: 0.6971\n","Epoch 54/200\n","16/16 [==============================] - 12s 723ms/step - loss: 0.4029 - accuracy: 0.9024 - val_loss: 0.8594 - val_accuracy: 0.7012\n","Epoch 55/200\n","16/16 [==============================] - 12s 722ms/step - loss: 0.4274 - accuracy: 0.8879 - val_loss: 0.8811 - val_accuracy: 0.7137\n","Epoch 56/200\n","16/16 [==============================] - 12s 723ms/step - loss: 0.4025 - accuracy: 0.9076 - val_loss: 0.8632 - val_accuracy: 0.7344\n","Epoch 57/200\n","16/16 [==============================] - 12s 724ms/step - loss: 0.3895 - accuracy: 0.8982 - val_loss: 0.8373 - val_accuracy: 0.7095\n","Epoch 58/200\n","16/16 [==============================] - 12s 726ms/step - loss: 0.3927 - accuracy: 0.9107 - val_loss: 0.8379 - val_accuracy: 0.7137\n","Epoch 59/200\n","16/16 [==============================] - 12s 727ms/step - loss: 0.3844 - accuracy: 0.9055 - val_loss: 0.8112 - val_accuracy: 0.7220\n","Epoch 60/200\n","16/16 [==============================] - 12s 728ms/step - loss: 0.3630 - accuracy: 0.9200 - val_loss: 0.8031 - val_accuracy: 0.7220\n","Epoch 61/200\n","16/16 [==============================] - 12s 725ms/step - loss: 0.3726 - accuracy: 0.9086 - val_loss: 0.8238 - val_accuracy: 0.7137\n","Epoch 62/200\n","16/16 [==============================] - 12s 723ms/step - loss: 0.3818 - accuracy: 0.9076 - val_loss: 0.8511 - val_accuracy: 0.7427\n","Epoch 63/200\n","16/16 [==============================] - 12s 722ms/step - loss: 0.4328 - accuracy: 0.8899 - val_loss: 0.8649 - val_accuracy: 0.7178\n","Epoch 64/200\n","16/16 [==============================] - 12s 723ms/step - loss: 0.3983 - accuracy: 0.9034 - val_loss: 0.8284 - val_accuracy: 0.7178\n","Epoch 65/200\n","16/16 [==============================] - 12s 722ms/step - loss: 0.3628 - accuracy: 0.9346 - val_loss: 0.8312 - val_accuracy: 0.7261\n","Epoch 66/200\n","16/16 [==============================] - 12s 725ms/step - loss: 0.3825 - accuracy: 0.9045 - val_loss: 0.8517 - val_accuracy: 0.7137\n","Epoch 67/200\n","16/16 [==============================] - 12s 727ms/step - loss: 0.3712 - accuracy: 0.9107 - val_loss: 0.8139 - val_accuracy: 0.7261\n","Epoch 68/200\n","16/16 [==============================] - 12s 722ms/step - loss: 0.3707 - accuracy: 0.9107 - val_loss: 0.8353 - val_accuracy: 0.7178\n","Epoch 69/200\n","16/16 [==============================] - 12s 721ms/step - loss: 0.3498 - accuracy: 0.9263 - val_loss: 0.8538 - val_accuracy: 0.7095\n","Epoch 70/200\n","16/16 [==============================] - 12s 723ms/step - loss: 0.3668 - accuracy: 0.9107 - val_loss: 0.8468 - val_accuracy: 0.7012\n","Epoch 71/200\n","16/16 [==============================] - 12s 726ms/step - loss: 0.3874 - accuracy: 0.9003 - val_loss: 0.8311 - val_accuracy: 0.7427\n","Epoch 72/200\n","16/16 [==============================] - 12s 725ms/step - loss: 0.3325 - accuracy: 0.9242 - val_loss: 0.8365 - val_accuracy: 0.7261\n","Epoch 73/200\n","16/16 [==============================] - 12s 730ms/step - loss: 0.3157 - accuracy: 0.9387 - val_loss: 0.8114 - val_accuracy: 0.7137\n","Epoch 74/200\n","16/16 [==============================] - 12s 727ms/step - loss: 0.3256 - accuracy: 0.9252 - val_loss: 0.8338 - val_accuracy: 0.7012\n","Epoch 75/200\n","16/16 [==============================] - 12s 725ms/step - loss: 0.3188 - accuracy: 0.9304 - val_loss: 0.8218 - val_accuracy: 0.7095\n","Epoch 76/200\n","16/16 [==============================] - 12s 732ms/step - loss: 0.3047 - accuracy: 0.9325 - val_loss: 0.8157 - val_accuracy: 0.7303\n","Epoch 77/200\n","16/16 [==============================] - 12s 726ms/step - loss: 0.3443 - accuracy: 0.9128 - val_loss: 0.8291 - val_accuracy: 0.7054\n","Epoch 78/200\n","16/16 [==============================] - 12s 726ms/step - loss: 0.3035 - accuracy: 0.9273 - val_loss: 0.8194 - val_accuracy: 0.7054\n","Epoch 79/200\n","16/16 [==============================] - 12s 727ms/step - loss: 0.2879 - accuracy: 0.9429 - val_loss: 0.8173 - val_accuracy: 0.7178\n","Epoch 80/200\n","16/16 [==============================] - 12s 727ms/step - loss: 0.3094 - accuracy: 0.9346 - val_loss: 0.8569 - val_accuracy: 0.7054\n","Epoch 81/200\n","16/16 [==============================] - 12s 722ms/step - loss: 0.4089 - accuracy: 0.8827 - val_loss: 0.9391 - val_accuracy: 0.6763\n","Epoch 82/200\n","16/16 [==============================] - 12s 725ms/step - loss: 0.3557 - accuracy: 0.8962 - val_loss: 0.8407 - val_accuracy: 0.6846\n","Epoch 83/200\n","16/16 [==============================] - 12s 726ms/step - loss: 0.3300 - accuracy: 0.9221 - val_loss: 0.9038 - val_accuracy: 0.6639\n","Epoch 84/200\n","16/16 [==============================] - 12s 727ms/step - loss: 0.3343 - accuracy: 0.9076 - val_loss: 0.8184 - val_accuracy: 0.7012\n","Epoch 85/200\n","16/16 [==============================] - 12s 729ms/step - loss: 0.2974 - accuracy: 0.9221 - val_loss: 0.8285 - val_accuracy: 0.7178\n","Epoch 86/200\n","16/16 [==============================] - 12s 728ms/step - loss: 0.2853 - accuracy: 0.9398 - val_loss: 0.8260 - val_accuracy: 0.7054\n","Epoch 87/200\n","16/16 [==============================] - 12s 722ms/step - loss: 0.3522 - accuracy: 0.9034 - val_loss: 0.8606 - val_accuracy: 0.6971\n","Epoch 88/200\n","16/16 [==============================] - 12s 723ms/step - loss: 0.3754 - accuracy: 0.9034 - val_loss: 0.8853 - val_accuracy: 0.6929\n","Epoch 89/200\n","16/16 [==============================] - 12s 725ms/step - loss: 0.3219 - accuracy: 0.9211 - val_loss: 0.8112 - val_accuracy: 0.7344\n","Epoch 90/200\n","16/16 [==============================] - 12s 725ms/step - loss: 0.2888 - accuracy: 0.9418 - val_loss: 0.8350 - val_accuracy: 0.7386\n","Epoch 91/200\n","16/16 [==============================] - 12s 727ms/step - loss: 0.2670 - accuracy: 0.9512 - val_loss: 0.7852 - val_accuracy: 0.7220\n","Epoch 92/200\n","16/16 [==============================] - 12s 728ms/step - loss: 0.2891 - accuracy: 0.9294 - val_loss: 0.8448 - val_accuracy: 0.7303\n","Epoch 93/200\n","16/16 [==============================] - 12s 727ms/step - loss: 0.3112 - accuracy: 0.9242 - val_loss: 0.8646 - val_accuracy: 0.7012\n","Epoch 94/200\n","16/16 [==============================] - 12s 725ms/step - loss: 0.3363 - accuracy: 0.9128 - val_loss: 1.0121 - val_accuracy: 0.6846\n","Epoch 95/200\n","16/16 [==============================] - 12s 727ms/step - loss: 0.3575 - accuracy: 0.8982 - val_loss: 0.8927 - val_accuracy: 0.7137\n","Epoch 96/200\n","16/16 [==============================] - 12s 725ms/step - loss: 0.3089 - accuracy: 0.9242 - val_loss: 0.8764 - val_accuracy: 0.7095\n","Epoch 97/200\n","16/16 [==============================] - 12s 726ms/step - loss: 0.2923 - accuracy: 0.9335 - val_loss: 0.8802 - val_accuracy: 0.7178\n","Epoch 98/200\n","16/16 [==============================] - 12s 729ms/step - loss: 0.2686 - accuracy: 0.9398 - val_loss: 0.8221 - val_accuracy: 0.7137\n","Epoch 99/200\n","16/16 [==============================] - 12s 728ms/step - loss: 0.2772 - accuracy: 0.9387 - val_loss: 0.7901 - val_accuracy: 0.7261\n","Epoch 100/200\n","16/16 [==============================] - 12s 727ms/step - loss: 0.2915 - accuracy: 0.9273 - val_loss: 0.8795 - val_accuracy: 0.7054\n","Epoch 101/200\n","16/16 [==============================] - 12s 730ms/step - loss: 0.3386 - accuracy: 0.9086 - val_loss: 0.9021 - val_accuracy: 0.6929\n","Epoch 102/200\n","16/16 [==============================] - 12s 731ms/step - loss: 0.2902 - accuracy: 0.9232 - val_loss: 0.8553 - val_accuracy: 0.7261\n","Epoch 103/200\n","16/16 [==============================] - 12s 725ms/step - loss: 0.3182 - accuracy: 0.9211 - val_loss: 0.8136 - val_accuracy: 0.7303\n","Epoch 104/200\n","16/16 [==============================] - 12s 730ms/step - loss: 0.2581 - accuracy: 0.9356 - val_loss: 0.8213 - val_accuracy: 0.7054\n","Epoch 105/200\n","16/16 [==============================] - 12s 732ms/step - loss: 0.2640 - accuracy: 0.9439 - val_loss: 0.8205 - val_accuracy: 0.7220\n","Epoch 106/200\n","16/16 [==============================] - 12s 732ms/step - loss: 0.2608 - accuracy: 0.9418 - val_loss: 0.8386 - val_accuracy: 0.7344\n","Epoch 107/200\n","16/16 [==============================] - 12s 724ms/step - loss: 0.2805 - accuracy: 0.9232 - val_loss: 0.8791 - val_accuracy: 0.7095\n","Epoch 108/200\n","16/16 [==============================] - 12s 727ms/step - loss: 0.2572 - accuracy: 0.9429 - val_loss: 0.7775 - val_accuracy: 0.7344\n","Epoch 109/200\n","16/16 [==============================] - 12s 728ms/step - loss: 0.2465 - accuracy: 0.9553 - val_loss: 0.7868 - val_accuracy: 0.7178\n","Epoch 110/200\n","16/16 [==============================] - 12s 730ms/step - loss: 0.2403 - accuracy: 0.9460 - val_loss: 0.7980 - val_accuracy: 0.7344\n","Epoch 111/200\n","16/16 [==============================] - 12s 728ms/step - loss: 0.2683 - accuracy: 0.9346 - val_loss: 0.7897 - val_accuracy: 0.7303\n","Epoch 112/200\n","16/16 [==============================] - 12s 727ms/step - loss: 0.2500 - accuracy: 0.9502 - val_loss: 0.7563 - val_accuracy: 0.7510\n","Epoch 113/200\n","16/16 [==============================] - 12s 729ms/step - loss: 0.2902 - accuracy: 0.9221 - val_loss: 0.7868 - val_accuracy: 0.7386\n","Epoch 114/200\n","16/16 [==============================] - 12s 728ms/step - loss: 0.2929 - accuracy: 0.9159 - val_loss: 0.7988 - val_accuracy: 0.7261\n","Epoch 115/200\n","16/16 [==============================] - 12s 729ms/step - loss: 0.2766 - accuracy: 0.9263 - val_loss: 0.7952 - val_accuracy: 0.7261\n","Epoch 116/200\n","16/16 [==============================] - 12s 726ms/step - loss: 0.2556 - accuracy: 0.9335 - val_loss: 0.8226 - val_accuracy: 0.7178\n","Epoch 117/200\n","16/16 [==============================] - 12s 727ms/step - loss: 0.2316 - accuracy: 0.9564 - val_loss: 0.8834 - val_accuracy: 0.7178\n","Epoch 118/200\n","16/16 [==============================] - 12s 729ms/step - loss: 0.2842 - accuracy: 0.9242 - val_loss: 0.8840 - val_accuracy: 0.7054\n","Epoch 119/200\n","16/16 [==============================] - 12s 729ms/step - loss: 0.2256 - accuracy: 0.9470 - val_loss: 0.8285 - val_accuracy: 0.7054\n","Epoch 120/200\n","16/16 [==============================] - 12s 728ms/step - loss: 0.2462 - accuracy: 0.9470 - val_loss: 0.8110 - val_accuracy: 0.7303\n","Epoch 121/200\n","16/16 [==============================] - 12s 728ms/step - loss: 0.2485 - accuracy: 0.9408 - val_loss: 0.7913 - val_accuracy: 0.6929\n","Epoch 122/200\n","16/16 [==============================] - 12s 727ms/step - loss: 0.2207 - accuracy: 0.9626 - val_loss: 0.7781 - val_accuracy: 0.7220\n","Epoch 123/200\n","16/16 [==============================] - 12s 729ms/step - loss: 0.2277 - accuracy: 0.9512 - val_loss: 0.7563 - val_accuracy: 0.7261\n","Epoch 124/200\n","16/16 [==============================] - 12s 729ms/step - loss: 0.2226 - accuracy: 0.9553 - val_loss: 0.7573 - val_accuracy: 0.7137\n","Epoch 125/200\n","16/16 [==============================] - 12s 729ms/step - loss: 0.2326 - accuracy: 0.9553 - val_loss: 0.7961 - val_accuracy: 0.7137\n","Epoch 126/200\n","16/16 [==============================] - 12s 734ms/step - loss: 0.2141 - accuracy: 0.9585 - val_loss: 0.8224 - val_accuracy: 0.7137\n","Epoch 127/200\n","16/16 [==============================] - 12s 736ms/step - loss: 0.2086 - accuracy: 0.9605 - val_loss: 0.7762 - val_accuracy: 0.7137\n","Epoch 128/200\n","16/16 [==============================] - 12s 730ms/step - loss: 0.2309 - accuracy: 0.9491 - val_loss: 0.8402 - val_accuracy: 0.6971\n","Epoch 129/200\n","16/16 [==============================] - 12s 728ms/step - loss: 0.2488 - accuracy: 0.9450 - val_loss: 0.8300 - val_accuracy: 0.7303\n","Epoch 130/200\n","16/16 [==============================] - 12s 730ms/step - loss: 0.2455 - accuracy: 0.9439 - val_loss: 0.8301 - val_accuracy: 0.7220\n","Epoch 131/200\n","16/16 [==============================] - 12s 729ms/step - loss: 0.2850 - accuracy: 0.9190 - val_loss: 0.8694 - val_accuracy: 0.7137\n","Epoch 132/200\n","16/16 [==============================] - 12s 730ms/step - loss: 0.2757 - accuracy: 0.9190 - val_loss: 0.8357 - val_accuracy: 0.7344\n","Epoch 133/200\n","16/16 [==============================] - 12s 729ms/step - loss: 0.2263 - accuracy: 0.9512 - val_loss: 0.7783 - val_accuracy: 0.7427\n","Epoch 134/200\n","16/16 [==============================] - 12s 727ms/step - loss: 0.2783 - accuracy: 0.9346 - val_loss: 0.8338 - val_accuracy: 0.7261\n","Epoch 135/200\n","16/16 [==============================] - 12s 732ms/step - loss: 0.2257 - accuracy: 0.9543 - val_loss: 0.8383 - val_accuracy: 0.7220\n","Epoch 136/200\n","16/16 [==============================] - 12s 727ms/step - loss: 0.2448 - accuracy: 0.9470 - val_loss: 0.8209 - val_accuracy: 0.7386\n","Epoch 137/200\n","16/16 [==============================] - 12s 729ms/step - loss: 0.2105 - accuracy: 0.9605 - val_loss: 0.8052 - val_accuracy: 0.7303\n","Epoch 138/200\n","16/16 [==============================] - 12s 730ms/step - loss: 0.2232 - accuracy: 0.9491 - val_loss: 0.8226 - val_accuracy: 0.7178\n","Epoch 139/200\n","16/16 [==============================] - 12s 731ms/step - loss: 0.2036 - accuracy: 0.9564 - val_loss: 0.7840 - val_accuracy: 0.7303\n","Epoch 140/200\n","16/16 [==============================] - 12s 731ms/step - loss: 0.2013 - accuracy: 0.9626 - val_loss: 0.8554 - val_accuracy: 0.7220\n","Epoch 141/200\n","16/16 [==============================] - 12s 728ms/step - loss: 0.2104 - accuracy: 0.9574 - val_loss: 0.8571 - val_accuracy: 0.7012\n","Epoch 142/200\n","16/16 [==============================] - 12s 729ms/step - loss: 0.1970 - accuracy: 0.9657 - val_loss: 0.8879 - val_accuracy: 0.7178\n","Epoch 143/200\n","16/16 [==============================] - 12s 724ms/step - loss: 0.2191 - accuracy: 0.9460 - val_loss: 0.8715 - val_accuracy: 0.6929\n","Epoch 144/200\n","16/16 [==============================] - 12s 729ms/step - loss: 0.2130 - accuracy: 0.9491 - val_loss: 0.7970 - val_accuracy: 0.7303\n","Epoch 145/200\n","16/16 [==============================] - 12s 731ms/step - loss: 0.2248 - accuracy: 0.9481 - val_loss: 0.8023 - val_accuracy: 0.7303\n","Epoch 146/200\n","16/16 [==============================] - 12s 729ms/step - loss: 0.2096 - accuracy: 0.9574 - val_loss: 0.8409 - val_accuracy: 0.7054\n","Epoch 147/200\n","16/16 [==============================] - 12s 730ms/step - loss: 0.2096 - accuracy: 0.9522 - val_loss: 0.8063 - val_accuracy: 0.7303\n","Epoch 148/200\n","16/16 [==============================] - 12s 728ms/step - loss: 0.2223 - accuracy: 0.9470 - val_loss: 0.8089 - val_accuracy: 0.7137\n","Epoch 149/200\n","16/16 [==============================] - 12s 729ms/step - loss: 0.2028 - accuracy: 0.9491 - val_loss: 0.8226 - val_accuracy: 0.7303\n","Epoch 150/200\n","16/16 [==============================] - 12s 727ms/step - loss: 0.2149 - accuracy: 0.9460 - val_loss: 0.8275 - val_accuracy: 0.7303\n","Epoch 151/200\n","16/16 [==============================] - 12s 733ms/step - loss: 0.2166 - accuracy: 0.9429 - val_loss: 0.7973 - val_accuracy: 0.7427\n","Epoch 152/200\n","16/16 [==============================] - 12s 737ms/step - loss: 0.2204 - accuracy: 0.9450 - val_loss: 0.9322 - val_accuracy: 0.7137\n","Epoch 153/200\n","16/16 [==============================] - 12s 732ms/step - loss: 0.2928 - accuracy: 0.9148 - val_loss: 0.9131 - val_accuracy: 0.7178\n","Epoch 154/200\n","16/16 [==============================] - 12s 731ms/step - loss: 0.2416 - accuracy: 0.9408 - val_loss: 0.8491 - val_accuracy: 0.7137\n","Epoch 155/200\n","16/16 [==============================] - 12s 730ms/step - loss: 0.2176 - accuracy: 0.9533 - val_loss: 0.8003 - val_accuracy: 0.7303\n","Epoch 156/200\n","16/16 [==============================] - 12s 729ms/step - loss: 0.2450 - accuracy: 0.9367 - val_loss: 0.8075 - val_accuracy: 0.7427\n","Epoch 157/200\n","16/16 [==============================] - 12s 732ms/step - loss: 0.2001 - accuracy: 0.9605 - val_loss: 0.8611 - val_accuracy: 0.7676\n","Epoch 158/200\n","16/16 [==============================] - 12s 730ms/step - loss: 0.2331 - accuracy: 0.9439 - val_loss: 0.8341 - val_accuracy: 0.7469\n","Epoch 159/200\n","16/16 [==============================] - 12s 731ms/step - loss: 0.2208 - accuracy: 0.9450 - val_loss: 0.8230 - val_accuracy: 0.7427\n","Epoch 160/200\n","16/16 [==============================] - 12s 734ms/step - loss: 0.2252 - accuracy: 0.9408 - val_loss: 0.8441 - val_accuracy: 0.7261\n","Epoch 161/200\n","16/16 [==============================] - 12s 730ms/step - loss: 0.2018 - accuracy: 0.9470 - val_loss: 0.8212 - val_accuracy: 0.7344\n","Epoch 162/200\n","16/16 [==============================] - 12s 732ms/step - loss: 0.1879 - accuracy: 0.9637 - val_loss: 0.8682 - val_accuracy: 0.7303\n","Epoch 163/200\n","16/16 [==============================] - 12s 730ms/step - loss: 0.2023 - accuracy: 0.9574 - val_loss: 0.8171 - val_accuracy: 0.7344\n","Epoch 164/200\n","16/16 [==============================] - 12s 729ms/step - loss: 0.2023 - accuracy: 0.9533 - val_loss: 0.8255 - val_accuracy: 0.7344\n","Epoch 165/200\n","16/16 [==============================] - 12s 732ms/step - loss: 0.1911 - accuracy: 0.9533 - val_loss: 0.8794 - val_accuracy: 0.7220\n","Epoch 166/200\n","16/16 [==============================] - 12s 726ms/step - loss: 0.1802 - accuracy: 0.9709 - val_loss: 0.8759 - val_accuracy: 0.7261\n","Epoch 167/200\n","16/16 [==============================] - 12s 729ms/step - loss: 0.2163 - accuracy: 0.9491 - val_loss: 0.8889 - val_accuracy: 0.7220\n","Epoch 168/200\n","16/16 [==============================] - 12s 726ms/step - loss: 0.2202 - accuracy: 0.9502 - val_loss: 0.7976 - val_accuracy: 0.7303\n","Epoch 169/200\n","16/16 [==============================] - 12s 728ms/step - loss: 0.2766 - accuracy: 0.9252 - val_loss: 0.8788 - val_accuracy: 0.7137\n","Epoch 170/200\n","16/16 [==============================] - 12s 731ms/step - loss: 0.2278 - accuracy: 0.9439 - val_loss: 0.8913 - val_accuracy: 0.7095\n","Epoch 171/200\n","16/16 [==============================] - 12s 730ms/step - loss: 0.2293 - accuracy: 0.9460 - val_loss: 0.8332 - val_accuracy: 0.7054\n","Epoch 172/200\n","16/16 [==============================] - 12s 728ms/step - loss: 0.2115 - accuracy: 0.9408 - val_loss: 0.8363 - val_accuracy: 0.7303\n","Epoch 173/200\n","16/16 [==============================] - 12s 729ms/step - loss: 0.2226 - accuracy: 0.9439 - val_loss: 0.8534 - val_accuracy: 0.7012\n","Epoch 174/200\n","16/16 [==============================] - 12s 731ms/step - loss: 0.1998 - accuracy: 0.9564 - val_loss: 0.9046 - val_accuracy: 0.7095\n","Epoch 175/200\n","16/16 [==============================] - 12s 728ms/step - loss: 0.2382 - accuracy: 0.9356 - val_loss: 0.8757 - val_accuracy: 0.7012\n","Epoch 176/200\n","16/16 [==============================] - 12s 727ms/step - loss: 0.1855 - accuracy: 0.9626 - val_loss: 0.8312 - val_accuracy: 0.7510\n","Epoch 177/200\n","16/16 [==============================] - 12s 734ms/step - loss: 0.1947 - accuracy: 0.9522 - val_loss: 0.8476 - val_accuracy: 0.7137\n","Epoch 178/200\n","16/16 [==============================] - 12s 735ms/step - loss: 0.1931 - accuracy: 0.9553 - val_loss: 0.8695 - val_accuracy: 0.7012\n","Epoch 179/200\n","16/16 [==============================] - 12s 729ms/step - loss: 0.1986 - accuracy: 0.9626 - val_loss: 0.8125 - val_accuracy: 0.7386\n","Epoch 180/200\n","16/16 [==============================] - 12s 729ms/step - loss: 0.1743 - accuracy: 0.9657 - val_loss: 0.7992 - val_accuracy: 0.7344\n","Epoch 181/200\n","16/16 [==============================] - 12s 723ms/step - loss: 0.1829 - accuracy: 0.9668 - val_loss: 0.8243 - val_accuracy: 0.7012\n","Epoch 182/200\n","16/16 [==============================] - 12s 725ms/step - loss: 0.1780 - accuracy: 0.9595 - val_loss: 0.8435 - val_accuracy: 0.7012\n","Epoch 183/200\n","16/16 [==============================] - 12s 729ms/step - loss: 0.1775 - accuracy: 0.9678 - val_loss: 0.8406 - val_accuracy: 0.7012\n","Epoch 184/200\n","16/16 [==============================] - 12s 728ms/step - loss: 0.1955 - accuracy: 0.9585 - val_loss: 0.8560 - val_accuracy: 0.7095\n","Epoch 185/200\n","16/16 [==============================] - 12s 729ms/step - loss: 0.1880 - accuracy: 0.9491 - val_loss: 0.8343 - val_accuracy: 0.7261\n","Epoch 186/200\n","16/16 [==============================] - 12s 728ms/step - loss: 0.2256 - accuracy: 0.9377 - val_loss: 0.8816 - val_accuracy: 0.7303\n","Epoch 187/200\n","16/16 [==============================] - 12s 729ms/step - loss: 0.1992 - accuracy: 0.9543 - val_loss: 0.8101 - val_accuracy: 0.7386\n","Epoch 188/200\n","16/16 [==============================] - 12s 726ms/step - loss: 0.1716 - accuracy: 0.9709 - val_loss: 0.8161 - val_accuracy: 0.7510\n","Epoch 189/200\n","16/16 [==============================] - 12s 725ms/step - loss: 0.2189 - accuracy: 0.9377 - val_loss: 0.8997 - val_accuracy: 0.7095\n","Epoch 190/200\n","16/16 [==============================] - 12s 730ms/step - loss: 0.2043 - accuracy: 0.9512 - val_loss: 0.8524 - val_accuracy: 0.7303\n","Epoch 191/200\n","16/16 [==============================] - 12s 729ms/step - loss: 0.1565 - accuracy: 0.9740 - val_loss: 0.8124 - val_accuracy: 0.7386\n","Epoch 192/200\n","16/16 [==============================] - 12s 728ms/step - loss: 0.1539 - accuracy: 0.9751 - val_loss: 0.8344 - val_accuracy: 0.7303\n","Epoch 193/200\n","16/16 [==============================] - 12s 731ms/step - loss: 0.1729 - accuracy: 0.9616 - val_loss: 0.8196 - val_accuracy: 0.7344\n","Epoch 194/200\n","16/16 [==============================] - 12s 727ms/step - loss: 0.2177 - accuracy: 0.9533 - val_loss: 0.9564 - val_accuracy: 0.7386\n","Epoch 195/200\n","16/16 [==============================] - 12s 730ms/step - loss: 0.1868 - accuracy: 0.9543 - val_loss: 0.8849 - val_accuracy: 0.7303\n","Epoch 196/200\n","16/16 [==============================] - 12s 725ms/step - loss: 0.1736 - accuracy: 0.9605 - val_loss: 0.7939 - val_accuracy: 0.7344\n","Epoch 197/200\n","16/16 [==============================] - 12s 729ms/step - loss: 0.1395 - accuracy: 0.9772 - val_loss: 0.8088 - val_accuracy: 0.7303\n","Epoch 198/200\n","16/16 [==============================] - 12s 730ms/step - loss: 0.1622 - accuracy: 0.9647 - val_loss: 0.8684 - val_accuracy: 0.7178\n","Epoch 199/200\n","16/16 [==============================] - 12s 729ms/step - loss: 0.1473 - accuracy: 0.9730 - val_loss: 0.7959 - val_accuracy: 0.7427\n","Epoch 200/200\n","16/16 [==============================] - 12s 729ms/step - loss: 0.1286 - accuracy: 0.9865 - val_loss: 0.7943 - val_accuracy: 0.7593\n","10/10 [==============================] - 5s 520ms/step - loss: 0.8672 - accuracy: 0.7649\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.8672488331794739, 0.7649006843566895]"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"jDsKrgiJR-G0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597420482826,"user_tz":180,"elapsed":724,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}},"outputId":"7125462a-5f8d-42b7-e576-ae1d5ef6cecc"},"source":["y_all"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([5, 5, 5, ..., 0, 0, 0], dtype=uint8)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"kPzLj9CBQtOZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596761114396,"user_tz":180,"elapsed":617,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}},"outputId":"05b8547b-bb1e-4b9a-c63e-f122c9b3e581"},"source":["y.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(64727,)"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"NzIq_PbjEvuP","colab_type":"code","colab":{}},"source":["###############################################################################\n","# Pipeline setup\n","# --------------\n","# We start by specifying the dimensions of our processing pipeline along with\n","# some other parameters.\n","#\n","# First, we have signal length. Longer signals are truncated and shorter\n","# signals are zero-padded. The sampling rate is 8000 Hz, so this corresponds to\n","# little over a second.\n","\n","T = 2 ** 14\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3T9hakC6HNde","colab_type":"code","colab":{}},"source":["# Maximum scale 2**J of the scattering transform (here, about 30 milliseconds)\n","# and the number of wavelets per octave.\n","J = 8\n","Q = 12"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IUffmPjjHOFG","colab_type":"code","colab":{}},"source":["# We need a small constant to add to the scattering coefficients before\n","# computing the logarithm. This prevents very large values when the scattering\n","# coefficients are very close to zero.\n","log_eps = 1e-6"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_LWjWHvn41am","colab_type":"code","colab":{}},"source":["info_data = fetch_fsdd()\n","files = info_data['files']\n","path_dataset = info_data['path_dataset']\n","\n","\n","teste = []\n","for k,w in enumerate(df['path']):\n","  teste.append([k,w])\n","teste"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nuz3_HJqMl5i","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":129},"executionInfo":{"status":"error","timestamp":1597452837447,"user_tz":180,"elapsed":723,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}},"outputId":"c31e5ace-da37-46c1-cce4-1f71d83ef92d"},"source":["_, x = wavfile.read('/content/eight/012c8314_nohash_0.wav')\n","x = np.asarray(x, dtype='float')\n","x /= np.max(np.abs(x))\n","\n","resample = "],"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-97250d5500e4>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    resample =\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","metadata":{"id":"YwlMZXLbNNjV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":286},"executionInfo":{"status":"ok","timestamp":1596674373063,"user_tz":180,"elapsed":965,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}},"outputId":"77a68ebf-359f-41e8-820d-49a60d45ddcc"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(x)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7fdc566dc240>]"]},"metadata":{"tags":[]},"execution_count":14},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"2VXsuUV7NOh7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":231},"executionInfo":{"status":"error","timestamp":1596752818415,"user_tz":180,"elapsed":1866,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}},"outputId":"76bdeb00-02d1-492d-ad44-83f660c9bb8f"},"source":["# If it's too long, truncate it.\n","if len(x) > T:\n","    x = x[:T]\n","\n","    # If it's too short, zero-pad it.\n","    start = (T - len(x)) // 2\n","\n","    x_all[k,start:start + len(x)] = x\n","    y_all[k] = y"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-254b64dbabf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# If it's too long, truncate it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# If it's too short, zero-pad it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"]}]},{"cell_type":"code","metadata":{"id":"YQs025d_NdR_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":377},"executionInfo":{"status":"ok","timestamp":1596950263760,"user_tz":180,"elapsed":21807,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}},"outputId":"8b6e7ba7-7acd-4df1-f297-2ab68d8b2ab5"},"source":["###############################################################################\n","# Log-scattering layer\n","# --------------------\n","# We now create a classification model using the `Scattering1D` Keras layer.\n","# First, we take the input signals of length `T`.\n","\n","x_in = layers.Input(shape=(T))\n","\n","###############################################################################\n","# These are fed into the `Scattering1D` layer.\n","\n","x = Scattering1D(J, Q=Q)(x_in)\n","\n","###############################################################################"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7f2d295a7268> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: Unable to identify source code of lambda function <function <lambda> at 0x7f2d295a7268>. It was defined in this code:\n","backend.fft = FFT(lambda x: tf.signal.fft(x, name='fft1d'),\n","                  lambda x: tf.signal.ifft(x, name='ifft1d'),\n","                  lambda x: tf.math.real(tf.signal.ifft(x, name='irfft1d')),\n","                  lambda x: None)\n","\n","This code must contain a single distinguishable lambda. To avoid this problem, define each lambda in a separate expression.\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <function <lambda> at 0x7f2d295a7268> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: Unable to identify source code of lambda function <function <lambda> at 0x7f2d295a7268>. It was defined in this code:\n","backend.fft = FFT(lambda x: tf.signal.fft(x, name='fft1d'),\n","                  lambda x: tf.signal.ifft(x, name='ifft1d'),\n","                  lambda x: tf.math.real(tf.signal.ifft(x, name='irfft1d')),\n","                  lambda x: None)\n","\n","This code must contain a single distinguishable lambda. To avoid this problem, define each lambda in a separate expression.\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SnVn-ILnN3re","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596674562181,"user_tz":180,"elapsed":425,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}},"outputId":"e06f5385-054b-4c61-9696-7fc068757f14"},"source":["x"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor 'scattering1d/Reshape_674:0' shape=(None, 337, 64) dtype=float32>"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"fogNE6vnOChy","colab_type":"code","colab":{}},"source":["###############################################################################\n","# Loading the data\n","# ----------------\n","# Once the parameter are set, we can start loading the data into a format that\n","# can be fed into the scattering transform and then a logistic regression\n","# classifier.\n","#\n","# We first download the dataset. If it's already downloaded, `fetch_fsdd` will\n","# simply return the information corresponding to the dataset that's already\n","# on disk.\n","\n","from scipy.io import wavfile\n","\n","info_data = fetch_fsdd()\n","files = info_data['files']\n","path_dataset = info_data['path_dataset']\n","\n","###############################################################################\n","# Set up NumPy arrays to hold the audio signals (`x_all`), the labels\n","# (`y_all`), and whether the signal is in the train or test set (`subset`).\n","\n","x_all = np.zeros((len(files), T))\n","y_all = np.zeros(len(files), dtype=np.uint8)\n","subset = np.zeros(len(files), dtype=np.uint8)\n","\n","###############################################################################\n","# For each file in the dataset, we extract its label `y` and its index from the\n","# filename. If the index is between 0 and 4, it is placed in the test set, while\n","# files with larger indices are used for training. The actual signals are\n","# normalized to have maximum amplitude one, and are truncated or zero-padded\n","# to the desired length `T`. They are then stored in the `x_all` array while\n","# their labels are in `y_all`.\n","\n","for k, f in enumerate(files):\n","    basename = f.split('.')[0]\n","\n","    # Get label (0-9) of recording.\n","    y = int(basename.split('_')[0])\n","\n","    # Index larger than 5 gets assigned to training set.\n","    if int(basename.split('_')[2]) >= 5:\n","        subset[k] = 0\n","    else:\n","        subset[k] = 1\n","\n","    # Load the audio signal and normalize it.\n","    _, x = wavfile.read(os.path.join(path_dataset, f))\n","    x = np.asarray(x, dtype='float')\n","    x /= np.max(np.abs(x))\n","\n","    # If it's too long, truncate it.\n","    if len(x) > T:\n","        x = x[:T]\n","\n","    # If it's too short, zero-pad it.\n","    start = (T - len(x)) // 2\n","\n","    x_all[k,start:start + len(x)] = x\n","    y_all[k] = y\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lvg3murIuUr8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596852743689,"user_tz":180,"elapsed":668,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}},"outputId":"238756f5-4dc1-402e-d411-f841d6db6369"},"source":["x_all.shape\n","np.unique(y_all)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","metadata":{"id":"8ehtOy_CAf5V","colab_type":"code","colab":{}},"source":["###############################################################################\n","# Log-scattering layer\n","# --------------------\n","# We now create a classification model using the `Scattering1D` Keras layer.\n","# First, we take the input signals of length `T`.\n","\n","x_in = layers.Input(shape=(T))\n","\n","###############################################################################\n","# These are fed into the `Scattering1D` layer.\n","\n","x = Scattering1D(J, Q=Q)(x_in)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_ZtCjnjAAtk_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596950330644,"user_tz":180,"elapsed":2238,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}},"outputId":"04ce7fe4-74d8-4ed9-d195-ac8c70110f05"},"source":["Q"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["24"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"Buy5yGRuOcyP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596951046053,"user_tz":180,"elapsed":712811,"user":{"displayName":"Timóteo de Rezende Potin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfXfsQSCx63Dxq8eri_9lJvro2J4iiFwXiyBU6Bg=s64","userId":"06856639183403278569"}},"outputId":"c1b02fd7-e4de-47b3-d82d-80818c0ec632"},"source":["###############################################################################\n","# Since it does not carry useful information, we remove the zeroth-order\n","# scattering coefficients, which are always placed in the first channel of\n","# the scattering transform.\n","\n","x = layers.Lambda(lambda x: x[..., 1:, :])(x)\n","\n","# To increase discriminability, we take the logarithm of the scattering\n","# coefficients (after adding a small constant to make sure nothing blows up\n","# when scattering coefficients are close to zero). This is known as the\n","# log-scattering transform.\n","\n","x = layers.Lambda(lambda x: tf.math.log(tf.abs(x) + log_eps))(x)\n","\n","###############################################################################\n","# We then average along the last dimension (time) to get a time-shift\n","# invariant representation.\n","\n","x = layers.GlobalAveragePooling1D(data_format='channels_first')(x)\n","\n","###############################################################################\n","# Finally, we apply batch normalization to ensure that the data is within a\n","# moderate range.\n","\n","x = layers.BatchNormalization(axis=1)(x)\n","\n","###############################################################################\n","# These features are then used to classify the input signal using a dense\n","# layer followed by a softmax activation.\n","\n","x_out = layers.Dense(10, activation='softmax')(x)\n","\n","###############################################################################\n","# Finally, we create the model and display it.\n","\n","model = tf.keras.models.Model(x_in, x_out)\n","model.summary()\n","\n","###############################################################################\n","# Training the classifier\n","# -----------------------\n","# Having set up the model, we attach an Adam optimizer and a cross-entropy\n","# loss function.\n","\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","###############################################################################\n","# We then train the model using `model.fit`. The training data is given by\n","# those indices satisfying `subset == 0`.\n","\n","model.fit(x_all[subset == 0], y_all[subset == 0], epochs=50,\n","          batch_size=64, validation_split=0.2)\n","\n","###############################################################################\n","# Finally, we evaluate the model on the held-out test data. These are given by\n","# the indices `subset == 1`.\n","\n","model.evaluate(x_all[subset == 1], y_all[subset == 1], verbose=2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"functional_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 16384)]           0         \n","_________________________________________________________________\n","scattering1d_1 (Scattering1D (None, 616, 64)           0         \n","_________________________________________________________________\n","lambda (Lambda)              (None, 615, 64)           0         \n","_________________________________________________________________\n","lambda_1 (Lambda)            (None, 615, 64)           0         \n","_________________________________________________________________\n","global_average_pooling1d (Gl (None, 615)               0         \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 615)               2460      \n","_________________________________________________________________\n","dense (Dense)                (None, 10)                6160      \n","=================================================================\n","Total params: 8,620\n","Trainable params: 7,390\n","Non-trainable params: 1,230\n","_________________________________________________________________\n","Epoch 1/50\n","29/29 [==============================] - 36s 1s/step - loss: 1.6594 - accuracy: 0.4450 - val_loss: 15.4995 - val_accuracy: 0.0800\n","Epoch 2/50\n","29/29 [==============================] - 12s 425ms/step - loss: 0.7567 - accuracy: 0.7806 - val_loss: 15.3430 - val_accuracy: 0.0800\n","Epoch 3/50\n","29/29 [==============================] - 12s 424ms/step - loss: 0.5568 - accuracy: 0.8378 - val_loss: 15.4758 - val_accuracy: 0.0800\n","Epoch 4/50\n","29/29 [==============================] - 12s 425ms/step - loss: 0.4674 - accuracy: 0.8700 - val_loss: 11.8992 - val_accuracy: 0.0800\n","Epoch 5/50\n","29/29 [==============================] - 12s 427ms/step - loss: 0.3987 - accuracy: 0.8917 - val_loss: 10.5390 - val_accuracy: 0.0800\n","Epoch 6/50\n","29/29 [==============================] - 12s 424ms/step - loss: 0.3653 - accuracy: 0.8994 - val_loss: 7.5662 - val_accuracy: 0.1178\n","Epoch 7/50\n","29/29 [==============================] - 12s 426ms/step - loss: 0.3311 - accuracy: 0.9144 - val_loss: 6.2226 - val_accuracy: 0.1133\n","Epoch 8/50\n","29/29 [==============================] - 12s 425ms/step - loss: 0.3157 - accuracy: 0.9144 - val_loss: 3.8286 - val_accuracy: 0.2178\n","Epoch 9/50\n","29/29 [==============================] - 12s 424ms/step - loss: 0.3049 - accuracy: 0.9117 - val_loss: 3.7060 - val_accuracy: 0.2378\n","Epoch 10/50\n","29/29 [==============================] - 12s 424ms/step - loss: 0.2714 - accuracy: 0.9372 - val_loss: 2.8468 - val_accuracy: 0.3556\n","Epoch 11/50\n","29/29 [==============================] - 12s 425ms/step - loss: 0.2635 - accuracy: 0.9294 - val_loss: 1.8296 - val_accuracy: 0.4600\n","Epoch 12/50\n","29/29 [==============================] - 12s 423ms/step - loss: 0.2389 - accuracy: 0.9400 - val_loss: 1.7000 - val_accuracy: 0.5244\n","Epoch 13/50\n","29/29 [==============================] - 13s 435ms/step - loss: 0.2380 - accuracy: 0.9361 - val_loss: 0.9153 - val_accuracy: 0.7133\n","Epoch 14/50\n","29/29 [==============================] - 12s 428ms/step - loss: 0.2232 - accuracy: 0.9450 - val_loss: 0.8759 - val_accuracy: 0.7422\n","Epoch 15/50\n","29/29 [==============================] - 12s 426ms/step - loss: 0.2222 - accuracy: 0.9472 - val_loss: 0.5857 - val_accuracy: 0.7956\n","Epoch 16/50\n","29/29 [==============================] - 12s 424ms/step - loss: 0.2082 - accuracy: 0.9444 - val_loss: 0.5219 - val_accuracy: 0.8289\n","Epoch 17/50\n","29/29 [==============================] - 12s 425ms/step - loss: 0.1910 - accuracy: 0.9556 - val_loss: 0.3792 - val_accuracy: 0.8689\n","Epoch 18/50\n","29/29 [==============================] - 12s 426ms/step - loss: 0.1919 - accuracy: 0.9511 - val_loss: 0.3703 - val_accuracy: 0.8711\n","Epoch 19/50\n","29/29 [==============================] - 12s 426ms/step - loss: 0.1945 - accuracy: 0.9478 - val_loss: 0.3305 - val_accuracy: 0.9022\n","Epoch 20/50\n","29/29 [==============================] - 12s 428ms/step - loss: 0.1741 - accuracy: 0.9594 - val_loss: 0.2716 - val_accuracy: 0.9244\n","Epoch 21/50\n","29/29 [==============================] - 12s 424ms/step - loss: 0.1746 - accuracy: 0.9600 - val_loss: 0.2619 - val_accuracy: 0.9333\n","Epoch 22/50\n","29/29 [==============================] - 12s 425ms/step - loss: 0.1863 - accuracy: 0.9461 - val_loss: 0.2516 - val_accuracy: 0.9244\n","Epoch 23/50\n","29/29 [==============================] - 12s 425ms/step - loss: 0.1803 - accuracy: 0.9522 - val_loss: 0.2593 - val_accuracy: 0.9356\n","Epoch 24/50\n","29/29 [==============================] - 12s 425ms/step - loss: 0.1711 - accuracy: 0.9528 - val_loss: 0.2609 - val_accuracy: 0.9356\n","Epoch 25/50\n","29/29 [==============================] - 12s 424ms/step - loss: 0.1561 - accuracy: 0.9656 - val_loss: 0.2449 - val_accuracy: 0.9356\n","Epoch 26/50\n","29/29 [==============================] - 12s 427ms/step - loss: 0.1508 - accuracy: 0.9594 - val_loss: 0.2194 - val_accuracy: 0.9378\n","Epoch 27/50\n","29/29 [==============================] - 12s 427ms/step - loss: 0.1483 - accuracy: 0.9644 - val_loss: 0.2159 - val_accuracy: 0.9511\n","Epoch 28/50\n","29/29 [==============================] - 12s 426ms/step - loss: 0.1400 - accuracy: 0.9639 - val_loss: 0.2198 - val_accuracy: 0.9400\n","Epoch 29/50\n","29/29 [==============================] - 12s 426ms/step - loss: 0.1321 - accuracy: 0.9678 - val_loss: 0.2106 - val_accuracy: 0.9444\n","Epoch 30/50\n","29/29 [==============================] - 12s 423ms/step - loss: 0.1412 - accuracy: 0.9622 - val_loss: 0.2276 - val_accuracy: 0.9400\n","Epoch 31/50\n","29/29 [==============================] - 12s 424ms/step - loss: 0.1553 - accuracy: 0.9600 - val_loss: 0.2337 - val_accuracy: 0.9289\n","Epoch 32/50\n","29/29 [==============================] - 12s 427ms/step - loss: 0.1392 - accuracy: 0.9644 - val_loss: 0.2459 - val_accuracy: 0.9400\n","Epoch 33/50\n","29/29 [==============================] - 12s 427ms/step - loss: 0.1324 - accuracy: 0.9667 - val_loss: 0.1950 - val_accuracy: 0.9511\n","Epoch 34/50\n","29/29 [==============================] - 12s 426ms/step - loss: 0.1252 - accuracy: 0.9722 - val_loss: 0.2024 - val_accuracy: 0.9467\n","Epoch 35/50\n","29/29 [==============================] - 12s 426ms/step - loss: 0.1315 - accuracy: 0.9650 - val_loss: 0.2218 - val_accuracy: 0.9222\n","Epoch 36/50\n","29/29 [==============================] - 12s 425ms/step - loss: 0.1446 - accuracy: 0.9578 - val_loss: 0.2241 - val_accuracy: 0.9378\n","Epoch 37/50\n","29/29 [==============================] - 12s 429ms/step - loss: 0.1273 - accuracy: 0.9667 - val_loss: 0.2018 - val_accuracy: 0.9444\n","Epoch 38/50\n","29/29 [==============================] - 12s 427ms/step - loss: 0.1159 - accuracy: 0.9672 - val_loss: 0.2032 - val_accuracy: 0.9444\n","Epoch 39/50\n","29/29 [==============================] - 12s 428ms/step - loss: 0.1172 - accuracy: 0.9656 - val_loss: 0.2082 - val_accuracy: 0.9356\n","Epoch 40/50\n","29/29 [==============================] - 12s 425ms/step - loss: 0.1242 - accuracy: 0.9689 - val_loss: 0.1973 - val_accuracy: 0.9444\n","Epoch 41/50\n","29/29 [==============================] - 12s 427ms/step - loss: 0.1172 - accuracy: 0.9656 - val_loss: 0.1932 - val_accuracy: 0.9400\n","Epoch 42/50\n","29/29 [==============================] - 12s 426ms/step - loss: 0.1063 - accuracy: 0.9767 - val_loss: 0.1969 - val_accuracy: 0.9489\n","Epoch 43/50\n","29/29 [==============================] - 12s 423ms/step - loss: 0.1124 - accuracy: 0.9728 - val_loss: 0.2144 - val_accuracy: 0.9400\n","Epoch 44/50\n","29/29 [==============================] - 12s 423ms/step - loss: 0.1165 - accuracy: 0.9700 - val_loss: 0.1993 - val_accuracy: 0.9489\n","Epoch 45/50\n","29/29 [==============================] - 12s 426ms/step - loss: 0.0950 - accuracy: 0.9811 - val_loss: 0.2002 - val_accuracy: 0.9467\n","Epoch 46/50\n","29/29 [==============================] - 12s 427ms/step - loss: 0.0966 - accuracy: 0.9794 - val_loss: 0.2130 - val_accuracy: 0.9467\n","Epoch 47/50\n","29/29 [==============================] - 12s 424ms/step - loss: 0.1088 - accuracy: 0.9728 - val_loss: 0.2015 - val_accuracy: 0.9422\n","Epoch 48/50\n","29/29 [==============================] - 12s 425ms/step - loss: 0.1155 - accuracy: 0.9667 - val_loss: 0.2058 - val_accuracy: 0.9533\n","Epoch 49/50\n","29/29 [==============================] - 12s 425ms/step - loss: 0.0974 - accuracy: 0.9783 - val_loss: 0.2115 - val_accuracy: 0.9489\n","Epoch 50/50\n","29/29 [==============================] - 12s 423ms/step - loss: 0.1079 - accuracy: 0.9728 - val_loss: 0.2100 - val_accuracy: 0.9400\n","8/8 - 2s - loss: 0.1623 - accuracy: 0.9480\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.16229890286922455, 0.9480000138282776]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"ZA-0zQiVQpmA","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ygKaecX04het","colab_type":"code","colab":{}},"source":["import os\n","import numpy as np\n","import pandas as pd\n","import random\n","    \n","from glob import glob\n","\n","from scipy.io import wavfile\n","from scipy import signal\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.decomposition import PCA\n","\n","from keras.utils import to_categorical\n","\n","\n","#pca = PCA(n_components=30)   \n","\n","\n","class DatasetGenerator_CWT():\n","    def __init__(self, label_set, \n","                 sample_rate=16000):\n","        \n","        self.label_set = label_set\n","        self.sample_rate = sample_rate\n","            \n","    # Covert string to numerical classes              \n","    def text_to_labels(self, text):\n","        return self.label_set.index(text)\n","    \n","    # Reverse translation of numerical classes back to characters\n","    def labels_to_text(self, labels):\n","        return self.label_set[labels]               \n","        \n","    def load_data(self, DIR):\n","\n","        # Get all paths inside DIR that ends with wav\n","        wav_files = glob(os.path.join(DIR, '*/*wav'))\n","        wav_files = [x.split(sep='/')[2] + '/' + x.split(sep='/')[3] for x in wav_files]\n","        \n","        # Loop over files to get samples\n","        data = []\n","        for e in wav_files:\n","            \n","            label, name = e.split('/')\n","            if label in self.label_set:\n","                label_id = self.text_to_labels(label)\n","                fle = os.path.join(DIR, e)\n","                \n","                sample = (label, label_id, name, fle)\n","                data.append(sample)\n","            else \n","\n","            \n","        # Data Frames with samples' labels and paths     \n","        df = pd.DataFrame(data, columns = ['label', 'label_id', 'user_id', 'wav_file'])\n","        \n","        self.df = df\n","        \n","        return self.df\n","\n","    def apply_train_test_split(self, test_size, random_state):\n","        \n","        self.df_train, self.df_test = train_test_split(self.df, \n","                                                       test_size=test_size,\n","                                                       random_state=random_state)\n","        \n","    def apply_train_val_split(self, val_size, random_state):\n","        \n","        self.df_train, self.df_val = train_test_split(self.df_train, \n","                                                      test_size=val_size, \n","                                                      random_state=random_state)\n","        \n","    def read_wav_file(self, x):\n","        # Read wavfile using scipy wavfile.read\n","        _, wav = wavfile.read(x) \n","        # Normalize\n","        wav = wav.astype(np.float32) / np.iinfo(np.int16).max\n","            \n","        return wav\n","    def process_wav_file(self, x, threshold_freq=5500, eps=1e-10):\n","        # Read wav file to array\n","        wav = self.read_wav_file(x)\n","        # Sample rate\n","        L = self.sample_rate\n","        # If longer then randomly truncate\n","        if len(wav) > L:\n","            i = np.random.randint(0, len(wav) - L)\n","            wav = wav[i:(i+L)]  \n","        # If shorter then randomly add silence\n","        elif len(wav) < L:\n","            rem_len = L - len(wav)\n","            silence_part = np.random.randint(-100,100,16000).astype(np.float32) / np.iinfo(np.int16).max\n","            j = np.random.randint(0, rem_len)\n","            silence_part_left  = silence_part[0:j]\n","            silence_part_right = silence_part[j:rem_len]\n","            wav = np.concatenate([silence_part_left, wav, silence_part_right])\n","        # Create spectrogram using continous wavelet transform (time-frequency representation)\n","        times,dt = np.linspace(0, 1, 16000, retstep=True)\n","        fs = 1/dt\n","        freqs = np.linspace(1, fs/2, 98)\n","        w = 6\n","        widths = w*fs / (2*freqs*np.pi)\n","        spec = signal.cwt(wav, signal.morlet2, widths, w=w)\n","        # Cut high frequencies\n","        #if threshold_freq is not None:\n","        #    spec = spec[freqs <= threshold_freq,:]\n","        #    freqs = freqs[freqs <= threshold_freq]\n","        # Log spectrogram\n","        amp = np.log(np.abs(spec)+eps)\n","        pca_test = pca.fit(amp)\n","        pca_data = pca.transform(amp)\n","        amp = pca_data\n","        #return amp \n","        return np.expand_dims(amp, axis=2) \n","\n","    def generator(self, batch_size, mode):\n","        while True:\n","            # Depending on mode select DataFrame with paths\n","            if mode == 'train':\n","                df = self.df_train \n","                ids = random.sample(range(df.shape[0]), df.shape[0])\n","            elif mode == 'val':\n","                df = self.df_val\n","                ids = list(range(df.shape[0]))\n","            elif mode == 'test':\n","                df = self.df_test\n","                ids = list(range(df.shape[0]))\n","            else:\n","                raise ValueError('The mode should be either train, val or test.')\n","                \n","            # Create batches (for training data the batches are randomly permuted)\n","            for start in range(0, len(ids), batch_size):\n","                X_batch = []\n","                if mode != 'test': \n","                    y_batch = []\n","                end = min(start + batch_size, len(ids))\n","                i_batch = ids[start:end]\n","                for i in i_batch:\n","                    X_batch.append(self.process_wav_file(df.wav_file.values[i]))\n","                    if mode != 'test':\n","                        y_batch.append(df.label_id.values[i])\n","                X_batch = np.array(X_batch)\n","\n","                if mode != 'test':\n","                    y_batch = to_categorical(y_batch, num_classes = len(self.label_set))\n","                    yield (X_batch, y_batch)\n","                else:\n","                    yield X_batch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VnQFJ6F6up_C","colab_type":"code","colab":{}},"source":["import numpy as np\n","import math\n","import warnings\n","from scipy.fftpack import ifft\n","\n","def adaptive_choice_P(sigma, eps=1e-7):\n","    \"\"\"\n","    Adaptive choice of the value of the number of periods in the frequency\n","    domain used to compute the Fourier transform of a Morlet wavelet.\n","\n","    This function considers a Morlet wavelet defined as the sum\n","    of\n","    * a Gabor term hat psi(omega) = hat g_{sigma}(omega - xi)\n","    where 0 < xi < 1 is some frequency and g_{sigma} is\n","    the Gaussian window defined in Fourier by\n","    hat g_{sigma}(omega) = e^{-omega^2/(2 sigma^2)}\n","    * a low pass term \\\\hat \\\\phi which is proportional to \\\\hat g_{\\\\sigma}.\n","\n","    If \\\\sigma is too large, then these formula will lead to discontinuities\n","    in the frequency interval [0, 1] (which is the interval used by numpy.fft).\n","    We therefore choose a larger integer P >= 1 such that at the boundaries\n","    of the Fourier transform of both filters on the interval [1-P, P], the\n","    magnitude of the entries is below the required machine precision.\n","    Mathematically, this means we would need P to satisfy the relations:\n","\n","    |\\\\hat \\\\psi(P)| <= eps and |\\\\hat \\\\phi(1-P)| <= eps\n","\n","    Since 0 <= xi <= 1, the latter implies the former. Hence the formula which\n","    is easily derived using the explicit formula for g_{\\\\sigma} in Fourier.\n","\n","    Parameters\n","    ----------\n","    sigma: float\n","        Positive number controlling the bandwidth of the filters\n","    eps : float, optional\n","        Positive number containing required precision. Defaults to 1e-7\n","\n","    Returns\n","    -------\n","    P : int\n","        integer controlling the number of periods used to ensure the\n","        periodicity of the final Morlet filter in the frequency interval\n","        [0, 1[. The value of P will lead to the use of the frequency\n","        interval [1-P, P[, so that there are 2*P - 1 periods.\n","    \"\"\"\n","    val = math.sqrt(-2 * (sigma**2) * math.log(eps))\n","    P = int(math.ceil(val + 1))\n","    return P\n","\n","\n","def periodize_filter_fourier(h_f, nperiods=1):\n","    \"\"\"\n","    Computes a periodization of a filter provided in the Fourier domain.\n","\n","    Parameters\n","    ----------\n","    h_f : array_like\n","        complex numpy array of shape (N*n_periods,)\n","    n_periods: int, optional\n","        Number of periods which should be used to periodize\n","\n","    Returns\n","    -------\n","    v_f : array_like\n","        complex numpy array of size (N,), which is a periodization of\n","        h_f as described in the formula:\n","        v_f[k] = sum_{i=0}^{n_periods - 1} h_f[i * N + k]\n","    \"\"\"\n","    N = h_f.shape[0] // nperiods\n","    v_f = h_f.reshape(nperiods, N).mean(axis=0)\n","    return v_f\n","\n","\n","def morlet_1d(N, xi, sigma, normalize='l1', P_max=5, eps=1e-7):\n","    \"\"\"\n","    Computes the Fourier transform of a Morlet filter.\n","\n","    A Morlet filter is the sum of a Gabor filter and a low-pass filter\n","    to ensure that the sum has exactly zero mean in the temporal domain.\n","    It is defined by the following formula in time:\n","    psi(t) = g_{sigma}(t) (e^{i xi t} - beta)\n","    where g_{sigma} is a Gaussian envelope, xi is a frequency and beta is\n","    the cancelling parameter.\n","\n","    Parameters\n","    ----------\n","    N : int\n","        size of the temporal support\n","    xi : float\n","        central frequency (in [0, 1])\n","    sigma : float\n","        bandwidth parameter\n","    normalize : string, optional\n","        normalization types for the filters. Defaults to 'l1'.\n","        Supported normalizations are 'l1' and 'l2' (understood in time domain).\n","    P_max: int, optional\n","        integer controlling the maximal number of periods to use to ensure\n","        the periodicity of the Fourier transform. (At most 2*P_max - 1 periods\n","        are used, to ensure an equal distribution around 0.5). Defaults to 5\n","        Should be >= 1\n","    eps : float\n","        required machine precision (to choose the adequate P)\n","\n","    Returns\n","    -------\n","    morlet_f : array_like\n","        numpy array of size (N,) containing the Fourier transform of the Morlet\n","        filter at the frequencies given by np.fft.fftfreq(N).\n","    \"\"\"\n","    if type(P_max) != int:\n","        raise ValueError('P_max should be an int, got {}'.format(type(P_max)))\n","    if P_max < 1:\n","        raise ValueError('P_max should be non-negative, got {}'.format(P_max))\n","    # Find the adequate value of P\n","    P = min(adaptive_choice_P(sigma, eps=eps), P_max)\n","    assert P >= 1\n","    # Define the frequencies over [1-P, P[\n","    freqs = np.arange((1 - P) * N, P * N, dtype=float) / float(N)\n","    if P == 1:\n","        # in this case, make sure that there is continuity around 0\n","        # by using the interval [-0.5, 0.5]\n","        freqs_low = np.fft.fftfreq(N)\n","    elif P > 1:\n","        freqs_low = freqs\n","    # define the gabor at freq xi and the low-pass, both of width sigma\n","    gabor_f = np.exp(-(freqs - xi)**2 / (2 * sigma**2))\n","    low_pass_f = np.exp(-(freqs_low**2) / (2 * sigma**2))\n","    # discretize in signal <=> periodize in Fourier\n","    gabor_f = periodize_filter_fourier(gabor_f, nperiods=2 * P - 1)\n","    low_pass_f = periodize_filter_fourier(low_pass_f, nperiods=2 * P - 1)\n","    # find the summation factor to ensure that morlet_f[0] = 0.\n","    kappa = gabor_f[0] / low_pass_f[0]\n","    morlet_f = gabor_f - kappa * low_pass_f\n","    # normalize the Morlet if necessary\n","    morlet_f *= get_normalizing_factor(morlet_f, normalize=normalize)\n","    return morlet_f\n","\n","\n","def get_normalizing_factor(h_f, normalize='l1'):\n","    \"\"\"\n","    Computes the desired normalization factor for a filter defined in Fourier.\n","\n","    Parameters\n","    ----------\n","    h_f : array_like\n","        numpy vector containing the Fourier transform of a filter\n","    normalized : string, optional\n","        desired normalization type, either 'l1' or 'l2'. Defaults to 'l1'.\n","\n","    Returns\n","    -------\n","    norm_factor : float\n","        such that h_f * norm_factor is the adequately normalized vector.\n","    \"\"\"\n","    h_real = ifft(h_f)\n","    if normalize == 'l1':\n","        norm_factor = 1. / (np.abs(h_real).sum())\n","    elif normalize == 'l2':\n","        norm_factor = 1. / np.sqrt((np.abs(h_real)**2).sum())\n","    else:\n","        raise ValueError(\"Supported normalizations only include 'l1' and 'l2'\")\n","    return norm_factor\n","\n","\n","def gauss_1d(N, sigma, normalize='l1', P_max=5, eps=1e-7):\n","    \"\"\"\n","    Computes the Fourier transform of a low pass gaussian window.\n","\n","    \\\\hat g_{\\\\sigma}(\\\\omega) = e^{-\\\\omega^2 / 2 \\\\sigma^2}\n","\n","    Parameters\n","    ----------\n","    N : int\n","        size of the temporal support\n","    sigma : float\n","        bandwidth parameter\n","    normalize : string, optional\n","        normalization types for the filters. Defaults to 'l1'\n","        Supported normalizations are 'l1' and 'l2' (understood in time domain).\n","    P_max : int, optional\n","        integer controlling the maximal number of periods to use to ensure\n","        the periodicity of the Fourier transform. (At most 2*P_max - 1 periods\n","        are used, to ensure an equal distribution around 0.5). Defaults to 5\n","        Should be >= 1\n","    eps : float, optional\n","        required machine precision (to choose the adequate P)\n","\n","    Returns\n","    -------\n","    g_f : array_like\n","        numpy array of size (N,) containing the Fourier transform of the\n","        filter (with the frequencies in the np.fft.fftfreq convention).\n","    \"\"\"\n","    # Find the adequate value of P\n","    if type(P_max) != int:\n","        raise ValueError('P_max should be an int, got {}'.format(type(P_max)))\n","    if P_max < 1:\n","        raise ValueError('P_max should be non-negative, got {}'.format(P_max))\n","    P = min(adaptive_choice_P(sigma, eps=eps), P_max)\n","    assert P >= 1\n","    # switch cases\n","    if P == 1:\n","        freqs_low = np.fft.fftfreq(N)\n","    elif P > 1:\n","        freqs_low = np.arange((1 - P) * N, P * N, dtype=float) / float(N)\n","    # define the low pass\n","    g_f = np.exp(-freqs_low**2 / (2 * sigma**2))\n","    # periodize it\n","    g_f = periodize_filter_fourier(g_f, nperiods=2 * P - 1)\n","    # normalize the signal\n","    g_f *= get_normalizing_factor(g_f, normalize=normalize)\n","    # return the Fourier transform\n","    return g_f\n","\n","\n","def compute_sigma_psi(xi, Q, r=math.sqrt(0.5)):\n","    \"\"\"\n","    Computes the frequential width sigma for a Morlet filter of frequency xi\n","    belonging to a family with Q wavelets.\n","\n","    The frequential width is adapted so that the intersection of the\n","    frequency responses of the next filter occurs at a r-bandwidth specified\n","    by r, to ensure a correct coverage of the whole frequency axis.\n","\n","    Parameters\n","    ----------\n","    xi : float\n","        frequency of the filter in [0, 1]\n","    Q : int\n","        number of filters per octave, Q is an integer >= 1\n","    r : float, optional\n","        Positive parameter defining the bandwidth to use.\n","        Should be < 1. We recommend keeping the default value.\n","        The larger r, the larger the filters in frequency domain.\n","\n","    Returns\n","    -------\n","    sigma : float\n","        frequential width of the Morlet wavelet.\n","\n","    Refs\n","    ----\n","    Convolutional operators in the time-frequency domain, V. Lostanlen,\n","    PhD Thesis, 2017\n","    https://tel.archives-ouvertes.fr/tel-01559667\n","    \"\"\"\n","    factor = 1. / math.pow(2, 1. / Q)\n","    term1 = (1 - factor) / (1 + factor)\n","    term2 = 1. / math.sqrt(2 * math.log(1. / r))\n","    return xi * term1 * term2\n","\n","\n","def compute_temporal_support(h_f, criterion_amplitude=1e-3):\n","    \"\"\"\n","    Computes the (half) temporal support of a family of centered,\n","    symmetric filters h provided in the Fourier domain\n","\n","    This function computes the support T which is the smallest integer\n","    such that for all signals x and all filters h,\n","\n","    \\\\| x \\\\conv h - x \\\\conv h_{[-T, T]} \\\\|_{\\\\infty} \\\\leq \\\\epsilon\n","        \\\\| x \\\\|_{\\\\infty}  (1)\n","\n","    where 0<\\\\epsilon<1 is an acceptable error, and h_{[-T, T]} denotes the\n","    filter h whose support is restricted in the interval [-T, T]\n","\n","    The resulting value T used to pad the signals to avoid boundary effects\n","    and numerical errors.\n","\n","    If the support is too small, no such T might exist.\n","    In this case, T is defined as the half of the support of h, and a\n","    UserWarning is raised.\n","\n","    Parameters\n","    ----------\n","    h_f : array_like\n","        a numpy array of size batch x time, where each row contains the\n","        Fourier transform of a filter which is centered and whose absolute\n","        value is symmetric\n","    criterion_amplitude : float, optional\n","        value \\\\epsilon controlling the numerical\n","        error. The larger criterion_amplitude, the smaller the temporal\n","        support and the larger the numerical error. Defaults to 1e-3\n","\n","    Returns\n","    -------\n","    t_max : int\n","        temporal support which ensures (1) for all rows of h_f\n","\n","    \"\"\"\n","    h = ifft(h_f, axis=1)\n","    half_support = h.shape[1] // 2\n","    # compute ||h - h_[-T, T]||_1\n","    l1_residual = np.fliplr(\n","        np.cumsum(np.fliplr(np.abs(h)[:, :half_support]), axis=1))\n","    # find the first point above criterion_amplitude\n","    if np.any(np.max(l1_residual, axis=0) <= criterion_amplitude):\n","        # if it is possible\n","        T = np.min(\n","            np.where(np.max(l1_residual, axis=0) <= criterion_amplitude)[0])\\\n","            + 1\n","    else:\n","        # if there is none:\n","        T = half_support\n","        # Raise a warning to say that there will be border effects\n","        warnings.warn('Signal support is too small to avoid border effects')\n","    return T\n","\n","\n","def get_max_dyadic_subsampling(xi, sigma, alpha=5.):\n","    \"\"\"\n","    Computes the maximal dyadic subsampling which is possible for a Gabor\n","    filter of frequency xi and width sigma\n","\n","    Finds the maximal integer j such that:\n","    omega_0 < 2^{-(j + 1)}\n","    where omega_0 is the boundary of the filter, defined as\n","    omega_0 = xi + alpha * sigma\n","\n","    This ensures that the filter can be subsampled by a factor 2^j without\n","    aliasing.\n","\n","    We use the same formula for Gabor and Morlet filters.\n","\n","    Parameters\n","    ----------\n","    xi : float\n","        frequency of the filter in [0, 1]\n","    sigma : float\n","        frequential width of the filter\n","    alpha : float, optional\n","        parameter controlling the error done in the aliasing.\n","        The larger alpha, the smaller the error. Defaults to 5.\n","\n","    Returns\n","    -------\n","    j : int\n","        integer such that 2^j is the maximal subsampling accepted by the\n","        Gabor filter without aliasing.\n","    \"\"\"\n","    upper_bound = min(xi + alpha * sigma, 0.5)\n","    j = math.floor(-math.log2(upper_bound)) - 1\n","    j = int(j)\n","    return j\n","\n","\n","def move_one_dyadic_step(cv, Q, alpha=5.):\n","    \"\"\"\n","    Computes the parameters of the next wavelet on the low frequency side,\n","    based on the parameters of the current wavelet.\n","\n","    This function is used in the loop defining all the filters, starting\n","    at the wavelet frequency and then going to the low frequencies by\n","    dyadic steps. This makes the loop in compute_params_filterbank much\n","    simpler to read.\n","\n","    The steps are defined as:\n","    xi_{n+1} = 2^{-1/Q} xi_n\n","    sigma_{n+1} = 2^{-1/Q} sigma_n\n","\n","    Parameters\n","    ----------\n","    cv : dictionary\n","        stands for current_value. Is a dictionary with keys:\n","        *'key': a tuple (j, n) where n is a counter and j is the maximal\n","            dyadic subsampling accepted by this wavelet.\n","        *'xi': central frequency of the wavelet\n","        *'sigma': width of the wavelet\n","    Q : int\n","        number of wavelets per octave. Controls the relationship between\n","        the frequency and width of the current wavelet and the next wavelet.\n","    alpha : float, optional\n","        tolerance parameter for the aliasing. The larger alpha,\n","        the more conservative the algorithm is. Defaults to 5.\n","\n","    Returns\n","    -------\n","    new_cv : dictionary\n","        a dictionary with the same keys as the ones listed for cv,\n","        whose values are updated\n","    \"\"\"\n","    factor = 1. / math.pow(2., 1. / Q)\n","    n = cv['key']\n","    new_cv = {'xi': cv['xi'] * factor, 'sigma': cv['sigma'] * factor}\n","    # compute the new j\n","    new_cv['j'] = get_max_dyadic_subsampling(new_cv['xi'], new_cv['sigma'], alpha=alpha)\n","    new_cv['key'] = n + 1\n","    return new_cv\n","\n","\n","def compute_xi_max(Q):\n","    \"\"\"\n","    Computes the maximal xi to use for the Morlet family, depending on Q.\n","\n","    Parameters\n","    ----------\n","    Q : int\n","        number of wavelets per octave (integer >= 1)\n","\n","    Returns\n","    -------\n","    xi_max : float\n","        largest frequency of the wavelet frame.\n","    \"\"\"\n","    xi_max = max(1. / (1. + math.pow(2., 3. / Q)), 0.35)\n","    return xi_max\n","\n","\n","def compute_params_filterbank(sigma_low, Q, r_psi=math.sqrt(0.5), alpha=5.):\n","    \"\"\"\n","    Computes the parameters of a Morlet wavelet filterbank.\n","\n","    This family is defined by constant ratios between the frequencies and\n","    width of adjacent filters, up to a minimum frequency where the frequencies\n","    are translated.\n","    This ensures that the low-pass filter has the largest temporal support\n","    among all filters, while preserving the coverage of the whole frequency\n","    axis.\n","\n","    The keys of the dictionaries are tuples of integers (j, n) where n is a\n","    counter (starting at 0 for the highest frequency filter) and j is the\n","    maximal dyadic subsampling accepted by this filter.\n","\n","    Parameters\n","    ----------\n","    sigma_low : float\n","        frequential width of the low-pass filter. This acts as a\n","        lower-bound on the frequential widths of the band-pass filters,\n","        so as to ensure that the low-pass filter has the largest temporal\n","        support among all filters.\n","    Q : int\n","        number of wavelets per octave.\n","    r_psi : float, optional\n","        Should be >0 and <1. Controls the redundancy of the filters\n","        (the larger r_psi, the larger the overlap between adjacent wavelets).\n","        Defaults to sqrt(0.5).\n","    alpha : float, optional\n","        tolerance factor for the aliasing after subsampling.\n","        The larger alpha, the more conservative the value of maximal\n","        subsampling is. Defaults to 5.\n","\n","    Returns\n","    -------\n","    xi : dictionary\n","        dictionary containing the central frequencies of the wavelets.\n","    sigma : dictionary\n","        dictionary containing the frequential widths of the wavelets.\n","\n","    Refs\n","    ----\n","    Convolutional operators in the time-frequency domain, 2.1.3, V. Lostanlen,\n","    PhD Thesis, 2017\n","    https://tel.archives-ouvertes.fr/tel-01559667\n","    \"\"\"\n","    xi_max = compute_xi_max(Q)\n","    sigma_max = compute_sigma_psi(xi_max, Q, r=r_psi)\n","\n","    xi = []\n","    sigma = []\n","    j = []\n","\n","    if sigma_max <= sigma_low:\n","        # in this exceptional case, we will not go through the loop, so\n","        # we directly assign\n","        last_xi = sigma_max\n","    else:\n","        # fill all the dyadic wavelets as long as possible\n","        current = {'key': 0, 'j': 0, 'xi': xi_max, 'sigma': sigma_max}\n","        while current['sigma'] > sigma_low:  # while we can attribute something\n","            xi.append(current['xi'])\n","            sigma.append(current['sigma'])\n","            j.append(current['j'])\n","            current = move_one_dyadic_step(current, Q, alpha=alpha)\n","        # get the last key\n","        last_xi = xi[-1]\n","    # fill num_interm wavelets between last_xi and 0, both excluded\n","    num_intermediate = Q - 1\n","    for q in range(1, num_intermediate + 1):\n","        factor = (num_intermediate + 1. - q) / (num_intermediate + 1.)\n","        new_xi = factor * last_xi\n","        new_sigma = sigma_low\n","        xi.append(new_xi)\n","        sigma.append(new_sigma)\n","        j.append(get_max_dyadic_subsampling(new_xi, new_sigma, alpha=alpha))\n","    # return results\n","    return xi, sigma, j\n","\n","\n","def calibrate_scattering_filters(J, Q, r_psi=math.sqrt(0.5), sigma0=0.1,\n","                                 alpha=5.):\n","    \"\"\"\n","    Calibrates the parameters of the filters used at the 1st and 2nd orders\n","    of the scattering transform.\n","\n","    These filterbanks share the same low-pass filterbank, but use a\n","    different Q: Q_1 = Q and Q_2 = 1.\n","\n","    The dictionaries for the band-pass filters have keys which are 2-tuples\n","    of the type (j, n), where n is an integer >=0 counting the filters (for\n","    identification purposes) and j is an integer >= 0 denoting the maximal\n","    subsampling 2**j which can be performed on a signal convolved with this\n","    filter without aliasing.\n","\n","    Parameters\n","    ----------\n","    J : int\n","        maximal scale of the scattering (controls the number of wavelets)\n","    Q : int\n","        number of wavelets per octave for the first order\n","    r_psi : float, optional\n","        Should be >0 and <1. Controls the redundancy of the filters\n","        (the larger r_psi, the larger the overlap between adjacent wavelets).\n","        Defaults to sqrt(0.5)\n","    sigma0 : float, optional\n","        frequential width of the low-pass filter at scale J=0\n","        (the subsequent widths are defined by sigma_J = sigma0 / 2^J).\n","        Defaults to 1e-1\n","    alpha : float, optional\n","        tolerance factor for the aliasing after subsampling.\n","        The larger alpha, the more conservative the value of maximal\n","        subsampling is. Defaults to 5.\n","\n","    Returns\n","    -------\n","    sigma_low : float\n","        frequential width of the low-pass filter\n","    xi1 : dictionary\n","        dictionary containing the center frequencies of the first order\n","        filters. See above for a decsription of the keys.\n","    sigma1 : dictionary\n","        dictionary containing the frequential width of the first order\n","        filters. See above for a description of the keys.\n","    xi2 : dictionary\n","        dictionary containing the center frequencies of the second order\n","        filters. See above for a decsription of the keys.\n","    sigma2 : dictionary\n","        dictionary containing the frequential width of the second order\n","        filters. See above for a description of the keys.\n","    \"\"\"\n","    if Q < 1:\n","        raise ValueError('Q should always be >= 1, got {}'.format(Q))\n","    sigma_low = sigma0 / math.pow(2, J)  # width of the low pass\n","    xi1, sigma1, j1 = compute_params_filterbank(sigma_low, Q, r_psi=r_psi,\n","                                            alpha=alpha)\n","    xi2, sigma2, j2 = compute_params_filterbank(sigma_low, 1, r_psi=r_psi,\n","                                            alpha=alpha)\n","    return sigma_low, xi1, sigma1, j1, xi2, sigma2, j2\n","\n","\n","def scattering_filter_factory(J_support, J_scattering, Q, r_psi=math.sqrt(0.5),\n","                              criterion_amplitude=1e-3, normalize='l1',\n","                              max_subsampling=None, sigma0=0.1, alpha=5.,\n","                              P_max=5, eps=1e-7, **kwargs):\n","    \"\"\"\n","    Builds in Fourier the Morlet filters used for the scattering transform.\n","\n","    Each single filter is provided as a dictionary with the following keys:\n","    * 'xi': central frequency, defaults to 0 for low-pass filters.\n","    * 'sigma': frequential width\n","    * k where k is an integer bounded below by 0. The maximal value for k\n","        depends on the type of filter, it is dynamically chosen depending\n","        on max_subsampling and the characteristics of the filters.\n","        Each value for k is an array (or tensor) of size 2**(J_support - k)\n","        containing the Fourier transform of the filter after subsampling by\n","        2**k\n","\n","    Parameters\n","    ----------\n","    J_support : int\n","        2**J_support is the desired support size of the filters\n","    J_scattering : int\n","        parameter for the scattering transform (2**J_scattering\n","        corresponds to the averaging support of the low-pass filter)\n","    Q : int\n","        number of wavelets per octave at the first order. For audio signals,\n","        a value Q >= 12 is recommended in order to separate partials.\n","    r_psi : float, optional\n","        Should be >0 and <1. Controls the redundancy of the filters\n","        (the larger r_psi, the larger the overlap between adjacent wavelets).\n","        Defaults to sqrt(0.5).\n","    criterion_amplitude : float, optional\n","        Represents the numerical error which is allowed to be lost after\n","        convolution and padding. Defaults to 1e-3.\n","    normalize : string, optional\n","        Normalization convention for the filters (in the\n","        temporal domain). Supported values include 'l1' and 'l2'; a ValueError\n","        is raised otherwise. Defaults to 'l1'.\n","    max_subsampling: int or None, optional\n","        maximal dyadic subsampling to compute, in order\n","        to save computation time if it is not required. Defaults to None, in\n","        which case this value is dynamically adjusted depending on the filters.\n","    sigma0 : float, optional\n","        parameter controlling the frequential width of the\n","        low-pass filter at J_scattering=0; at a an absolute J_scattering, it\n","        is equal to sigma0 / 2**J_scattering. Defaults to 1e-1\n","    alpha : float, optional\n","        tolerance factor for the aliasing after subsampling.\n","        The larger alpha, the more conservative the value of maximal\n","        subsampling is. Defaults to 5.\n","    P_max : int, optional\n","        maximal number of periods to use to make sure that the Fourier\n","        transform of the filters is periodic. P_max = 5 is more than enough for\n","        double precision. Defaults to 5. Should be >= 1\n","    eps : float, optional\n","        required machine precision for the periodization (single\n","        floating point is enough for deep learning applications).\n","        Defaults to 1e-7\n","\n","    Returns\n","    -------\n","    phi_f : dictionary\n","        a dictionary containing the low-pass filter at all possible\n","        subsamplings. See above for a description of the dictionary structure.\n","        The possible subsamplings are controlled by the inputs they can\n","        receive, which correspond to the subsamplings performed on top of the\n","        1st and 2nd order transforms.\n","    psi1_f : dictionary\n","        a dictionary containing the band-pass filters of the 1st order,\n","        only for the base resolution as no subsampling is used in the\n","        scattering tree.\n","        Each value corresponds to a dictionary for a single filter, see above\n","        for an exact description.\n","        The keys of this dictionary are of the type (j, n) where n is an\n","        integer counting the filters and j the maximal dyadic subsampling\n","        which can be performed on top of the filter without aliasing.\n","    psi2_f : dictionary\n","        a dictionary containing the band-pass filters of the 2nd order\n","        at all possible subsamplings. The subsamplings are determined by the\n","        input they can receive, which depends on the scattering tree.\n","        Each value corresponds to a dictionary for a single filter, see above\n","        for an exact description.\n","        The keys of this dictionary are of th etype (j, n) where n is an\n","        integer counting the filters and j is the maximal dyadic subsampling\n","        which can be performed on top of this filter without aliasing.\n","    t_max_phi : int\n","        temporal size to use to pad the signal on the right and on the\n","        left by making at most criterion_amplitude error. Assumes that the\n","        temporal support of the low-pass filter is larger than all filters.\n","\n","    Refs\n","    ----\n","    Convolutional operators in the time-frequency domain, V. Lostanlen,\n","    PhD Thesis, 2017\n","    https://tel.archives-ouvertes.fr/tel-01559667\n","    \"\"\"\n","    # compute the spectral parameters of the filters\n","    sigma_low, xi1, sigma1, j1s, xi2, sigma2, j2s = calibrate_scattering_filters(\n","        J_scattering, Q, r_psi=r_psi, sigma0=sigma0, alpha=alpha)\n","\n","    # instantiate the dictionaries which will contain the filters\n","    phi_f = {}\n","    psi1_f = []\n","    psi2_f = []\n","\n","    # compute the band-pass filters of the second order,\n","    # which can take as input a subsampled\n","    for (n2, j2) in enumerate(j2s):\n","        # compute the current value for the max_subsampling,\n","        # which depends on the input it can accept.\n","        if max_subsampling is None:\n","            possible_subsamplings_after_order1 = [\n","                j1 for j1 in j1s if j2 > j1]\n","            if len(possible_subsamplings_after_order1) > 0:\n","                max_sub_psi2 = max(possible_subsamplings_after_order1)\n","            else:\n","                max_sub_psi2 = 0\n","        else:\n","            max_sub_psi2 = max_subsampling\n","        # We first compute the filter without subsampling\n","        T = 2**J_support\n","\n","        psi_f = {}\n","        psi_f[0] = morlet_1d(\n","            T, xi2[n2], sigma2[n2], normalize=normalize, P_max=P_max,\n","            eps=eps)\n","        # compute the filter after subsampling at all other subsamplings\n","        # which might be received by the network, based on this first filter\n","        for subsampling in range(1, max_sub_psi2 + 1):\n","            factor_subsampling = 2**subsampling\n","            psi_f[subsampling] = periodize_filter_fourier(\n","                psi_f[0], nperiods=factor_subsampling)\n","        psi2_f.append(psi_f)\n","\n","    # for the 1st order filters, the input is not subsampled so we\n","    # can only compute them with T=2**J_support\n","    for (n1, j1) in enumerate(j1s):\n","        T = 2**J_support\n","        psi1_f.append({0: morlet_1d(\n","            T, xi1[n1], sigma1[n1], normalize=normalize,\n","            P_max=P_max, eps=eps)})\n","\n","    # compute the low-pass filters phi\n","    # Determine the maximal subsampling for phi, which depends on the\n","    # input it can accept (both 1st and 2nd order)\n","    if max_subsampling is None:\n","        max_subsampling_after_psi1 = max(j1s)\n","        max_subsampling_after_psi2 = max(j2s)\n","        max_sub_phi = max(max_subsampling_after_psi1,\n","                          max_subsampling_after_psi2)\n","    else:\n","        max_sub_phi = max_subsampling\n","\n","    # compute the filters at all possible subsamplings\n","    phi_f[0] = gauss_1d(T, sigma_low, P_max=P_max, eps=eps)\n","    for subsampling in range(1, max_sub_phi + 1):\n","        factor_subsampling = 2**subsampling\n","        # compute the low_pass filter\n","        phi_f[subsampling] = periodize_filter_fourier(\n","            phi_f[0], nperiods=factor_subsampling)\n","\n","    # Embed the meta information within the filters\n","    for (n1, j1) in enumerate(j1s):\n","        psi1_f[n1]['xi'] = xi1[n1]\n","        psi1_f[n1]['sigma'] = sigma1[n1]\n","        psi1_f[n1]['j'] = j1\n","    for (n2, j2) in enumerate(j2s):\n","        psi2_f[n2]['xi'] = xi2[n2]\n","        psi2_f[n2]['sigma'] = sigma2[n2]\n","        psi2_f[n2]['j'] = j2\n","    phi_f['xi'] = 0.\n","    phi_f['sigma'] = sigma_low\n","    phi_f['j'] = 0\n","\n","    # compute the support size allowing to pad without boundary errors\n","    # at the finest resolution\n","    t_max_phi = compute_temporal_support(\n","        phi_f[0].reshape(1, -1), criterion_amplitude=criterion_amplitude)\n","\n","    # return results\n","    return phi_f, psi1_f, psi2_f, t_max_phi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W4qpKg9vuq1Q","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}